[{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 beast2tpPipeline authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"vignette walk process using beast2tpPipeline package create SNP clusters set fasta files, create xml files cluster, run BEAST2, run TransPhylo BEAST2 results, kind regression probabilities assigned TransPhylo. running BEAST2, set posterior trees cluster. package can two things: Create maximum clade credibility (MCC) tree posterior trees, run TransPhylo multitree MCC trees, sharing parameters can simultaneously estimated. MCC tree single tree attempts summarize posterior trees, like mean median posterior samples values real line. method take one tree summarizes posterior trees cluster, run TransPhylo true phylogenetic trees. Subsample number trees BEAST2 posterior tree samples cluster, run TransPhylo sample trees cluster, rather one summary tree. advantage accounting phylogenetic uncertainty BEAST2 trees, rather assuming one tree truth. However, computationally expensive: instead one TransPhylo run clusters, run TransPhylo cluster separately, time decently-sized set trees. run computing cluster. Additionally, via method, parameter sharing possible. vignette, use package (1).","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"use package, need dependencies installed. can install following code: also need BEAST2 installed computer. can download . use package manager like homebrew, can install BEAST2 brew install beast2 terminal. install suite programs, including BEAST2, BEAUti, TreeAnnotator. probably also want install Tracer look traceplots diagnostics BEAST2 runs. can download Tracer . Next, install beast2tpPipeline package GitHub: , load package: package built step pipeline associated function. steps functions : Assigning SNP clusters: assign_snp_clusters takes set sequences metadata, assigns sequences SNP clusters. Creating BEAST2 clusters: create_BEAST2_clusters takes SNP clusters separates sequence data cluster, keeping SNPs. Creating XML files BEAST2: create_cluster_xml takes SNP data creates XML file BEAST2 run. Running BEAST2: run_beast2 runs BEAST2 XML file. take DNA sequences infer timed phylogenetic tree, tells us ancestry pathogen. Getting MCC trees: get_mcctree takes posterior trees BEAST2 creates maximum clade credibility tree - summary tree, like mean median. Running TransPhylo MCC trees: run_TransPhylo runs TransPhylo MCC trees, sharing parameters can simultaneously estimated. take timed phylogeny use try infer -infected-. Running regression TransPhylo results: regression runs linear logistic regression using TransPhylo results. draw inference relationship covariates individual transmission probabilities.","code":"install.packages(c(\"ape\", \"TransPhylo\", \"coda\", \"tracerer\", \"lubridate\", \"tidyverse\")) remotes::install_github(\"JamesStimson/transcluster\", build_vignettes = TRUE) devtools::install_github(\"jessalynnsebastian/beast2tpPipeline\", build_vignettes = TRUE) library(beast2tpPipeline)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"data-for-this-example","dir":"Articles","previous_headings":"","what":"Data for this Example","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"package comes data collected Kopanyo study, tuberculosis (TB) samples collected two regions Botswana, country high prevalence TB human immodeficiency virus (HIV). Read study . data contain 4 fasta files, one lineage TB. fasta file contains aligned TB sequences study participants. also metadata available samples, including things like HIV status, age, gender, sample collection date, handful variables. Suppose interested using TB sequences draw inference whether HIV makes individual likely transmit TB someone else.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"creating-single-nucleotide-polymorphism-snp-clusters","dir":"Articles","previous_headings":"","what":"Creating Single Nucleotide Polymorphism (SNP) Clusters","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"First, read fasta files metadata R. can take peek data: Notice 1426 sequences corresponding metadata. computationally intensive run BEAST2 sequences simultaneously. Instead, create clusters similar sequences run BEAST2 cluster separately. create clusters, use SNP thresholding. SNPs single nucleotide polymorphisms, single base pair differences sequences. can use differences group sequences clusters likely closely related . use transcluster package . transcluster package developed alongside paper Beyond SNP Threshold: Identifying Outbreak Clusters Using Inferred Transmissions. built handle plain SNP thresholding create clusters, also clustering based likely transmissions. use former, simpler commonly used, latter still available function. assign sequences clusters based SNPs, use assign_snp_clusters, wrapper around transcluster functions. Computing distance matrix large clusters can take time, already distance matrix saved, can pass assign_snp_clusters dist_matrix argument. Next, create actual BEAST2 clusters using create_BEAST2_clusters function. take sequences, split separate objects, keep SNPs (sites across sequences matter BEAST2), write fasta files used BEAUti create_cluster_xml. discard clusters fewer 4 sequences, clusters fewer 8 SNPs. also add constant sites sequences, deal ascertainment bias BEAST2 since keeping SNPs. save fasta files directory called BEAST2_clusters data directory project, using create_cluster_xml create xml files necessary BEAST2. using BEAUti create xml files, need saved fasta files cluster import BEAUti. Use argument fasta_dir save fasta files directory, otherwise leave default save fasta files.","code":"fasta_files <- list.files(system.file(\"kopanyo\", package = \"beast2tpPipeline\"),                           pattern = \".fasta\", full.names = TRUE) tb_sequences <- lapply(fasta_files, ape::read.dna, format = \"fasta\", as.character = TRUE)  metadata <- list.files(system.file(\"kopanyo\", package = \"beast2tpPipeline\"),                        pattern = \".csv\", full.names = TRUE) metadata <- read.csv(metadata) head(metadata) ##   SampleID Lineage genderf1 agenew hivfinal_new gMixture  collectdt smokef1 ## 1 BTB-1139       1        1     52            1        0 2014-07-30       1 ## 2 BTB-1146       1        1     43            1        1 2014-08-05       1 ## 3 BTB-1705       1        1     70            2        1 2015-06-10       1 ## 4  BTB-175       1        2     19            1        1 2013-01-16       2 ## 5 BTB-1774       1        1     38            1        1 2015-07-30       2 ## 6 BTB-1894       1        1     15           NA        1 2015-10-16       2 ##   tb_everf3 alcohol_excess Lineage_detailed ## 1         2              2            1.1.2 ## 2         2              1            1.1.2 ## 3         1              2            1.1.2 ## 4         1              2            1.1.2 ## 5         1              2            1.1.2 ## 6         1              2            1.1.2 dim(metadata) ## [1] 1426   11 # Get collection dates by lineage collectdts <- split(metadata, metadata$Lineage) # Create named vectors of dates, as required by the function collectdts <- lapply(collectdts, function(meta) {   dates <- meta$collectdt   names(dates) <- meta$SampleID   dates })  # TODO: REMOVE THIS WHEN TESTING IS DONE. tb_sequences <- tb_sequences[1:3] collectdts <- collectdts[1:3]  # Apply the function to each lineage of sequences cluster_assignments <- mapply(assign_snp_clusters,                               seqs = tb_sequences,                               collectdts = collectdts,                               threshold = 5,                               SIMPLIFY = FALSE) ## Creating SNP-based clusters ## Creating SNP-based clusters ## Creating SNP-based clusters # Take a look at the cluster assignments lapply(cluster_assignments, head) ## [[1]] ##   sample_id cluster_name  collectdt ## 1  BTB-1023     cluster1 2014-05-13 ## 2  BTB-1058     cluster2 2014-06-04 ## 3  BTB-1088     cluster3 2014-06-25 ## 4    BTB-10     cluster4 2012-09-10 ## 5  BTB-1133     cluster5 2014-07-25 ## 6  BTB-1139     cluster6 2014-07-30 ##  ## [[2]] ##   sample_id cluster_name  collectdt ## 1  BTB-1000     cluster1 2014-04-28 ## 2  BTB-1014     cluster2 2014-05-07 ## 3  BTB-1025     cluster3 2014-05-13 ## 4  BTB-1115     cluster4 2014-07-16 ## 5  BTB-1123     cluster5 2014-07-16 ## 6  BTB-1160     cluster6 2014-08-12 ##  ## [[3]] ##   sample_id cluster_name  collectdt ## 1   BTB-119     cluster1 2012-12-03 ## 2  BTB-1259     cluster2 2014-09-25 ## 3  BTB-1344     cluster3 2014-11-11 ## 4  BTB-1410     cluster1 2014-12-10 ## 5   BTB-155     cluster1 2013-01-07 ## 6  BTB-1698     cluster1 2015-06-08 # Rename clusters to include lineage cluster_assignments <- lapply(seq_along(cluster_assignments), function(i) {   cluster_assignments[[i]]$cluster_name <- paste0(\"lineage\", i, \"_\", cluster_assignments[[i]]$cluster_name)   cluster_assignments[[i]] }) # For each lineage, use the cluster assignments to put the sequences into clusters snp_matrices <- lapply(seq_along(tb_sequences), function(lineage_index) {   create_BEAST2_clusters(seqs = tb_sequences[[lineage_index]],                          snp_clusters = setNames(cluster_assignments[[lineage_index]]$cluster_name,                                                  cluster_assignments[[lineage_index]]$sample_id),                          min_cluster_size = 4,                          min_varsites = 8,                          snps_only = TRUE,                          constant_sites = \"acgt\") }) # Now we have a list of 4 lineages, each containing a list of clusters (data frames) within that lineage # Now that we won't be working with the fasta files themselves anymore, let's turn this list of lists into a list, # and let's turn the list of cluster assignments into a data frame snp_matrices <- unlist(snp_matrices, recursive = FALSE) cluster_assignments <- do.call(rbind, cluster_assignments) # For each cluster, create an xml file for BEAST2 invisible(lapply(names(snp_matrices), function(cluster_name) {   create_cluster_xml(seqs = snp_matrices[[cluster_name]],                      cluster_name = cluster_name,                      sampling_dates = setNames(cluster_assignments$collectdt[cluster_assignments$cluster_name == cluster_name],                                                cluster_assignments$sample_id[cluster_assignments$cluster_name == cluster_name]),                      out_dir = \"~/Code/beast2tpPipeline_example/BEAST2\") })) cores <- parallel::detectCores()/2 input_xml <- list.files(\"~/Code/beast2tpPipeline_example/BEAST2\", pattern = \"\\\\.xml\", full.names = TRUE) invisible(parallel::mclapply(input_xml, run_beast2, mc.cores = cores)) beast_logs <- list.files(\"~/Code/beast2tpPipeline_example/BEAST2\", pattern = \"\\\\.log\", full.names = TRUE) invisible(sapply(beast_logs, function(log) {   ess_checks(\"BEAST2\", log, min_ess = 200) })) trees_files <- list.files(\"~/Code/beast2tpPipeline_example/BEAST2\", pattern = \".trees\", full.names = TRUE) out_dir <- \"~/Code/beast2tpPipeline_example/BEAST2/mcctree\" invisible(parallel::mclapply(seq_along(trees_files), function(i) {   get_mcctree(input_treesfile = trees_files[i], output_dir = out_dir) }, mc.cores = cores)) # Read the trees and manipulate the names to make sure they match the names in cluster_assignments mcc_trees_files <- list.files(out_dir, pattern = \".tree\", full.names = TRUE) mcc_trees <- lapply(mcc_trees_files, ape::read.nexus) names(mcc_trees) <- gsub(\".nexus\", \"\", basename(mcc_trees_files)) names(mcc_trees) <- gsub(\".*-\", \"\", names(mcc_trees)) # Run TransPhylo on the MCC trees debugonce(run_TransPhylo) prob_source <- run_TransPhylo(mcc_trees,                               type = \"mcctrees\",                               cluster_dict = cluster_assignments,                               out_dir = \"~/Code/beast2tpPipeline_example/TransPhylo\",                               mcmc_iterations = 100,                               verbose = TRUE) # Get dataframe with covariates for regression cleaned_data <- metadata[, c(\"SampleID\", \"hivfinal_new\")] cleaned_data <- cleaned_data[complete.cases(cleaned_data), ] cleaned_data$hivfinal_new <- as.factor(cleaned_data$hivfinal_new - 1) # Run a linear model with the probabilities from TransPhylo mdl <- regression(method = \"linear\",                   cleaned_data = cleaned_data,                   prob_source = prob_source) summary(mdl)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jessalyn Sebastian. Author, maintainer.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Sebastian J (2024). beast2tpPipeline: BEAST2 TransPhylo Regression Pipeline. R package version 0.0.0.9000, https://jessalynnsebastian.github.io/beast2tpPipeline/.","code":"@Manual{,   title = {beast2tpPipeline: BEAST2 to TransPhylo to Regression Pipeline},   author = {Jessalyn Sebastian},   year = {2024},   note = {R package version 0.0.0.9000},   url = {https://jessalynnsebastian.github.io/beast2tpPipeline/}, }"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/assign_snp_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign SNP Clusters to Samples — assign_snp_clusters","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"function assigns SNP clusters samples based SNP distance threshold, , alternatively, based transmission clusters Stimson et al. paper, Beyond SNP Threshold: Identifying Outbreak Clusters Using Inferred Transmissions.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/assign_snp_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"","code":"assign_snp_clusters(   seqs,   collectdts,   snp_matrix = NULL,   threshold = 5,   clockrate = -1,   transm_rate = -1 )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/assign_snp_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"seqs Matrices containing sequences. collectdts numeric vector collection dates, names corresponding rownames seqs matrix. snp_matrix SNP distances previously computed, include argument avoid re-computing. threshold numeric value SNP threshold, transmission threshold using transmission clusters (see transcluster info). clockrate numeric value clock rate using transmission clusters. transm_rate numeric value transmission rate using transmission clusters.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/assign_snp_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"data frame containing sample ID, cluster name, collection date sample.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_BEAST2_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"Using SNP cluster information DNA sequences, separate sequences separate DNAbin objcts cluster. desired, keep SNPs.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_BEAST2_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"","code":"create_BEAST2_clusters(   seqs,   snp_clusters,   collectdts = NULL,   min_cluster_size = 4,   min_varsites = 8,   snps_only = TRUE,   constant_sites = \"\",   cluster_dictionary_file = NULL,   fasta_dir = NULL )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_BEAST2_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"seqs matrix DNA sequences, rownames correspond sample IDs, ape::DNAbin object. snp_clusters named vector SNP cluster assignments, names correspond sample IDs. collectdts named vector collection dates, names correspond sample IDs. Dates format \"YYYY-MM-DD\" decimal format. .character = TRUE). min_cluster_size number samples required keep cluster. cluster small, discard . min_varsites number variable sites required keep cluster. enough variable sites, discard cluster. snps_only TRUE, keep SNPs output DNAbin objects. constant_sites string constant sites add beginning sequence. necessary BEAST2 input using SNPs. Defaults empty string. cluster_dictionary_file Optionally, file path write cluster dictionary , containing cluster names, sizes, varsites. fasta_dir Optionally, directory write FASTA files cluster. FASTA files automatically named cluster names.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_BEAST2_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"named list matrices containing SNPs.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_cluster_xml.html","id":null,"dir":"Reference","previous_headings":"","what":"Create BEAST2 XML File — create_cluster_xml","title":"Create BEAST2 XML File — create_cluster_xml","text":"Use template XML file create new XML files BEAST2 input. function can replace sequences, sampling dates, mcmc iterations, frequency storing trees, , uniform clock rate, minimum maximum clock rates. designed just used provided template file, though theoretically used others. template file written tuberculosis data. contains adjustment ascertainment bias due SNPs, Gamma site model, HKY substitution model, strict clock, Coalescent constant population model, uniform clock rate prior (min/max editable), lognormal(1, 1.25) freqParameter, kappa, popsize priors. template xml contains placeholders: SNP_FILE_NAME_HERE name SNP file ALIGNMENT_INFORMATION_HERE sequence information DATE_INFORMATION_HERE sampling dates CLOCKRATE_MINIMUM_HERE minimum uniform clock rate CLOCKRATE_MAXIMUM_HERE maximum uniform clock rate CLOCKRATE_INITIAL_HERE initial clock rate MCMC_ITERATIONS_HERE number MCMC iterations STORE_EVERY_HERE frequency storing trees","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_cluster_xml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create BEAST2 XML File — create_cluster_xml","text":"","code":"create_cluster_xml(   path_to_template = system.file(\"xml_template/0_xml_template.xml\", package =     \"beast2tpPipeline\"),   seqs,   cluster_name,   sampling_dates,   mcmc_iterations = 1e+07,   store_every = 5000,   min_clockrate = 10^(-8),   max_clockrate = 5 * 10^(-7),   init_clockrate = 10 * min_clockrate,   whole_genome_length = 4.2 * 10^6,   out_dir )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_cluster_xml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create BEAST2 XML File — create_cluster_xml","text":"path_to_template path template XML file. seqs matrix DNA sequences (SNPs), rownames correspond sample IDs, ape::DNAbin object. cluster_name name cluster. sampling_dates named vector sampling dates, names corresponding sample IDs. Dates either decimal years format \"YYYY-MM-DD\". mcmc_iterations number MCMC iterations run. store_every frequency storing trees. min_clockrate minimum clock rate uniform clock rate prior. Defaults tuberculosis genome clock rate. adjust SNPs . max_clockrate maximum clock rate uniform clock rate prior. Defaults tuberculosis genome clock rate. init_clockrate initial clock rate clock rate. whole_genome_length length whole genome. Used adjust clock rate SNPs. Defaults TB length. out_dir directory write output XML file. Files automatically named FASTA names.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/ess_checks.html","id":null,"dir":"Reference","previous_headings":"","what":"Use Effective Sample Size to Check Mixing — ess_checks","title":"Use Effective Sample Size to Check Mixing — ess_checks","text":"BEAST2 run TransPhylo run, pull effective sample size estimated parameters. Check threshold.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/ess_checks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use Effective Sample Size to Check Mixing — ess_checks","text":"","code":"ess_checks(   program = c(\"BEAST2\", \"TransPhylo\"),   path_to_mcmc_log,   burn_in_fraction = 0.1,   sample_interval = 5000,   min_ess )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/ess_checks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use Effective Sample Size to Check Mixing — ess_checks","text":"program Character string. Either \"BEAST2\" \"TransPhylo\". path_to_mcmc_log Character string. Path MCMC log file. burn_in_fraction Numeric. Fraction MCMC chain discard burn-. sample_interval Numeric. Interval samples taken. min_ess Numeric. Minimum effective sample size consider acceptable.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_mcctree.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","title":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","text":"Run TreeAnnotator get maximum clade credibility tree BEAST2 tree file.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_mcctree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","text":"","code":"get_mcctree(   input_treesfile,   output_dir,   beast_iterations = 1e+07,   burnin_fraction = 1/2,   heights = \"CA\",   treeannotator_path = \"/Applications/\\\"BEAST 2.7.7\\\"/bin/treeannotator\" )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_mcctree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","text":"input_treesfile Character string. Path BEAST2 .trees file. output_dir Character string. Path desired output directory MCC tree nexus file. beast_iterations Numeric. Number iterations BEAST2 run. burnin_fraction Numeric. Fraction MCMC chain discard burn-. heights Character string. Node heights tree. Beware using anything common ancestor, get weird trees work TransPhylo. treeannotator_path Character string. Path TreeAnnotator executable.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Linear or Logistic Regression with TransPhylo Results — regression","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"function takes probability estimates TransPhylo runs linear regression , logistic regression probability cutoff label individual infection source specified.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"","code":"regression(   method = c(\"logistic\", \"linear\"),   cleaned_data,   prob_source,   prob_cutoff = NULL )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"method character string specifying type regression run. Can \"linear\" \"logistic\". cleaned_data data frame containing covariates use regression. Must contain column \"SampleID\" sample IDs. prob_source data frame probabilities output TransPhylo columns SampleID prob_source (output run_TransPhylo), indicating probability sample infection source. prob_cutoff numeric specifying probability cutoff use logistic regression. NULL, logistic regression run.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"lm glm object.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_TransPhylo.html","id":null,"dir":"Reference","previous_headings":"","what":"Run TransPhylo on a Set of Trees — run_TransPhylo","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"wrapper TransPhylo::infer_multittree_share_param. Can use run TransPhylo set trees, either MCC trees parameter sharing, sample posterior BEAST2 trees without parameter sharing (.e., sample BEAST2 posterior trees single cluster, incorporate phylogenetic uncertainty).","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_TransPhylo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"","code":"run_TransPhylo(   trees,   cluster_name = NULL,   type = c(\"mcctrees\", \"trees_sample\"),   cluster_dict,   out_dir = \"TransPhylo\",   output_name = \"tp_res\",   gentime_shape = 10,   gentime_scale = 1/10,   sampling_shape = 10,   sampling_scale = 1/10,   prior_sampfrac_a = 1,   prior_sampfrac_b = 19,   start_off_p = 0.5,   start_neg = 1.48,   start_pi = 0.5,   start_off_r = 1,   share = c(\"neg\", \"off.r\"),   update_neg = TRUE,   update_off_r = TRUE,   update_off_p = FALSE,   update_pi = TRUE,   optiStart = 2,   verbose = FALSE,   delta_t = 0.01,   mcmc_iterations = 1e+05,   thinning = 10 )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_TransPhylo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"trees ape multiPhylo object containing trees analyzed. type \"mcctrees\", MCC trees clusters, names trees need match names trees cluster dictionary. type \"trees_sample\", sample posterior BEAST2 trees single cluster, cluster name provided argument. cluster_name type \"trees_sample\", name cluster trees analyzed. match cluster name cluster dictionary. type \"mcctrees\", argument ignored. type character string specifying type trees analyzed. Can \"mcctrees\" \"trees_sample\". \"mcctrees\", function run TransPhylo MCC trees clusters. \"trees_sample\", function run TransPhylo sample posterior BEAST2 trees single cluster. cluster_dict data frame containing sample_id, cluster_name, collectdt sequence, output assign_snp_clusters. out_dir character string specifying directory TransPhylo results saved. output_name character string specifying name output file. gentime_shape numeric specifying shape parameter gamma distribution generation time. gentime_scale numeric specifying scale parameter gamma distribution generation time. sampling_shape numeric specifying shape parameter gamma distribution sampling time. Default gentime_shape. sampling_scale numeric specifying scale parameter gamma distribution sampling time. Default gentime_scale. prior_sampfrac_a numeric specifying first shape parameter beta distribution sampling fraction. prior_sampfrac_b numeric specifying second shape parameter beta distribution sampling fraction. start_off_p numeric specifying starting value .p parameter. start_neg numeric specifying starting value neg parameter. start_pi numeric specifying starting value pi parameter. start_off_r numeric specifying starting value .r parameter. share character vector specifying parameters share across clusters. Defaults \"neg\" \".r\". type \"trees_sample\", parameter ignored. update_neg logical specifying whether update neg parameter. update_off_r logical specifying whether update .r parameter. update_off_p logical specifying whether update .p parameter. update_pi logical specifying whether update pi parameter. optiStart numeric specifying type optimization apply MCMC start point. verbose logical specifying whether print verbose output. delta_t grid size MCMC. Smaller better slower. mcmc_iterations numeric specifying number MCMC iterations. thinning numeric specifying thinning parameter MCMC.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_TransPhylo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"data frame containing probability sample infection source.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_beast2.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Command-Line BEAST2 — run_beast2","title":"Run Command-Line BEAST2 — run_beast2","text":"Run BEAST2 XML file. Tree files, log files, etc. written directory XML file.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_beast2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Command-Line BEAST2 — run_beast2","text":"","code":"run_beast2(   input_xml_path,   beast2_path = \"/Applications/\\\"BEAST 2.7.7\\\"/bin/beast\" )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_beast2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Command-Line BEAST2 — run_beast2","text":"input_xml_path Character string. Path BEAST2 XML file. beast2_path Character string. Path BEAST2 executable.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/sample_BEAST2_trees.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample BEAST2 Trees — sample_BEAST2_trees","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"function takes BEAST2 posterior trees samples subset , making sure keep tree names.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/sample_BEAST2_trees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"","code":"sample_BEAST2_trees(trees_file, n_trees, seed = NULL, out_dir = NULL)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/sample_BEAST2_trees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"trees_file string path BEAST2 posterior trees file. n_trees integer number trees sample. seed Optionally, seed use tree sampling. out_dir Optionally, string directory write sampled trees .","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/sample_BEAST2_trees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"ape multiPhylo object containing tree sample.","code":""}]
