[{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 beast2tpPipeline authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"vignette walk process using beast2tpPipeline package create SNP clusters set fasta files, create xml files cluster, run BEAST2, run TransPhylo BEAST2 results, kind regression probabilities assigned TransPhylo. running BEAST2, set posterior trees cluster. package can two things: Create maximum clade credibility (MCC) tree posterior trees, run TransPhylo multitree MCC trees, sharing parameters can simultaneously estimated. MCC tree single tree attempts summarize posterior trees, like mean median posterior samples values real line. method take one tree summarizes posterior trees cluster, run TransPhylo true phylogenetic trees. Subsample number trees BEAST2 posterior tree samples cluster, run TransPhylo sample trees cluster, rather one summary tree. advantage accounting phylogenetic uncertainty BEAST2 trees, rather assuming one tree truth. However, computationally expensive: instead one TransPhylo run clusters, run TransPhylo cluster separately, time decently-sized set trees. run computing cluster. Additionally, via method, parameter sharing possible. vignette, use package (1). First, load package library.","code":"library(beast2tpPipeline)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"data-for-this-example","dir":"Articles","previous_headings":"","what":"Data for this Example","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"package comes data collected Kopanyo study, tuberculosis (TB) samples collected two regions Botswana, country high prevalence TB human immodeficiency virus (HIV). Read study . data contain 4 fasta files, one lineage TB. fasta file contains aligned TB sequences study participants. also metadata available samples, including things like HIV status, age, gender, sample collection date, handful variables. Suppose interested using TB sequences draw inference whether HIV makes individual likely transmit TB someone else.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"creating-single-nucleotide-polymorphism-snp-clusters","dir":"Articles","previous_headings":"","what":"Creating Single Nucleotide Polymorphism (SNP) Clusters","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"First, read fasta files metadata R. can take peek data: Notice 1426 sequences corresponding metadata. computationally intensive run BEAST2 sequences simultaneously. Instead, create clusters similar sequences run BEAST2 cluster separately. create clusters, use SNP thresholding. SNPs single nucleotide polymorphisms, single base pair differences sequences. can use differences group sequences clusters likely closely related . use transcluster package . transcluster package developed alongside paper Beyond SNP Threshold: Identifying Outbreak Clusters Using Inferred Transmissions. built handle plain SNP thresholding create clusters, also clustering based likely transmissions. use former, simpler commonly used, latter still available function. assign sequences clusters based SNPs, use assign_snp_clusters, wrapper around transcluster functions. Computing distance matrix large clusters can take time, already distance matrix saved, can pass assign_snp_clusters dist_matrix argument. Now : Next, create actual BEAST2 clusters using create_BEAST2_clusters function. take sequences, split separate objects, keep SNPs (sites across sequences matter BEAST2). discard clusters fewer 4 sequences, clusters fewer 8 SNPs. also add constant sites sequences, deal ascertainment bias BEAST2 due fact keeping SNPs. output function list matrices, matrix cluster sequences. use write xml file run BEAST2. using template xml file available package, save sequences fasta files loaded BEAUti, can providing fasta_dir argument function. running chunks, two objects: cluster_assignments, list lineages containing dataframe giving sample IDs, cluster names, collection dates; snp_matrices, list lineages containing list matrices, matrix cluster sequences.","code":"fasta_files <- list.files(system.file(\"kopanyo\", package = \"beast2tpPipeline\"),                           pattern = \".fasta\", full.names = TRUE) tb_sequences <- lapply(fasta_files, ape::read.dna, format = \"fasta\",                        as.character = TRUE)  metadata <- list.files(system.file(\"kopanyo\", package = \"beast2tpPipeline\"),                        pattern = \".csv\", full.names = TRUE) metadata <- read.csv(metadata) head(metadata) ##   SampleID Lineage genderf1 agenew hivfinal_new gMixture  collectdt smokef1 ## 1 BTB-1139       1        1     52            1        0 2014-07-30       1 ## 2 BTB-1146       1        1     43            1        1 2014-08-05       1 ## 3 BTB-1705       1        1     70            2        1 2015-06-10       1 ## 4  BTB-175       1        2     19            1        1 2013-01-16       2 ## 5 BTB-1774       1        1     38            1        1 2015-07-30       2 ## 6 BTB-1894       1        1     15           NA        1 2015-10-16       2 ##   tb_everf3 alcohol_excess Lineage_detailed ## 1         2              2            1.1.2 ## 2         2              1            1.1.2 ## 3         1              2            1.1.2 ## 4         1              2            1.1.2 ## 5         1              2            1.1.2 ## 6         1              2            1.1.2 dim(metadata) ## [1] 1426   11 # Get collection dates by lineage collectdts <- split(metadata, metadata$Lineage) # Create named vectors of dates, as required by the function collectdts <- lapply(collectdts, function(meta) {   dates <- meta$collectdt   names(dates) <- meta$SampleID   dates })  # Apply the function to each lineage of sequences cluster_assignments <- mapply(assign_snp_clusters,                               # `seqs` is a matrix of sequences                               seqs = tb_sequences,                               # `collectdts` is a named list of vectors of collection dates                               # where the elements are collection dates and the names are sample IDs                                 collectdts = collectdts,                               threshold = 5,                               SIMPLIFY = FALSE) ## Creating SNP-based clusters ## Creating SNP-based clusters ## Creating SNP-based clusters ## Creating SNP-based clusters # Rename clusters to include lineage cluster_assignments <- lapply(seq_along(cluster_assignments), function(i) {   cluster_assignments[[i]]$cluster_name <- paste0(\"lineage\", i, \"_\", cluster_assignments[[i]]$cluster_name)   cluster_assignments[[i]] })  # Take a look at the cluster assignments lapply(cluster_assignments, head) ## [[1]] ##   sample_id      cluster_name  collectdt ## 1  BTB-1023 lineage1_cluster1 2014-05-13 ## 2  BTB-1058 lineage1_cluster2 2014-06-04 ## 3  BTB-1088 lineage1_cluster3 2014-06-25 ## 4    BTB-10 lineage1_cluster4 2012-09-10 ## 5  BTB-1133 lineage1_cluster5 2014-07-25 ## 6  BTB-1139 lineage1_cluster6 2014-07-30 ##  ## [[2]] ##   sample_id      cluster_name  collectdt ## 1  BTB-1000 lineage2_cluster1 2014-04-28 ## 2  BTB-1014 lineage2_cluster2 2014-05-07 ## 3  BTB-1025 lineage2_cluster3 2014-05-13 ## 4  BTB-1115 lineage2_cluster4 2014-07-16 ## 5  BTB-1123 lineage2_cluster5 2014-07-16 ## 6  BTB-1160 lineage2_cluster6 2014-08-12 ##  ## [[3]] ##   sample_id      cluster_name  collectdt ## 1   BTB-119 lineage3_cluster1 2012-12-03 ## 2  BTB-1259 lineage3_cluster2 2014-09-25 ## 3  BTB-1344 lineage3_cluster3 2014-11-11 ## 4  BTB-1410 lineage3_cluster1 2014-12-10 ## 5   BTB-155 lineage3_cluster1 2013-01-07 ## 6  BTB-1698 lineage3_cluster1 2015-06-08 ##  ## [[4]] ##   sample_id      cluster_name  collectdt ## 1  BTB-1001 lineage4_cluster1 2014-04-28 ## 2  BTB-1003 lineage4_cluster2 2014-04-25 ## 3  BTB-1005 lineage4_cluster3 2014-04-30 ## 4  BTB-1007 lineage4_cluster4 2014-05-02 ## 5  BTB-1009 lineage4_cluster5 2014-05-05 ## 6  BTB-1010 lineage4_cluster6 2014-05-05 # For each lineage, use the cluster assignments to put the sequences # into clusters snp_matrices <- lapply(seq_along(tb_sequences), function(lineage_index) {   # Pull the sequences and cluster assignments for this lineage   tb_seq_lineage <- tb_sequences[[lineage_index]]   cluster_assignments_lineage <- cluster_assignments[[lineage_index]]   create_BEAST2_clusters(seqs = tb_seq_lineage,                          cluster_assignments = cluster_assignments_lineage,                          min_cluster_size = 4,                          min_varsites = 8,                          snps_only = TRUE,                          constant_sites = \"acgt\") })  # Take a look at the clusters from the first lineage snp_matrices[[1]] ## $lineage1_cluster6 ##          [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## BTB-1139 \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"c\"  \"t\"  \"c\"   \"c\"   \"t\"   \"c\"   ## BTB-1146 \"a\"  \"c\"  \"g\"  \"t\"  \"a\"  \"t\"  \"g\"  \"c\"  \"t\"  \"t\"   \"t\"   \"t\"   \"c\"   ## BTB-1705 \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"t\"  \"t\"  \"c\"   \"c\"   \"t\"   \"c\"   ## BTB-175  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"c\"  \"t\"  \"c\"   \"c\"   \"c\"   \"t\"   ## BTB-1774 \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"c\"  \"c\"  \"t\"  \"c\"   \"c\"   \"c\"   \"t\"   ## BTB-262  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"c\"  \"t\"  \"c\"   \"c\"   \"t\"   \"c\"   ## BTB-604  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"c\"  \"c\"  \"c\"   \"c\"   \"t\"   \"c\"   ##          [,14] [,15] [,16] [,17] [,18] ## BTB-1139 \"g\"   \"g\"   \"c\"   \"c\"   \"g\"   ## BTB-1146 \"g\"   \"g\"   \"c\"   \"c\"   \"a\"   ## BTB-1705 \"g\"   \"g\"   \"c\"   \"t\"   \"g\"   ## BTB-175  \"a\"   \"t\"   \"t\"   \"c\"   \"g\"   ## BTB-1774 \"a\"   \"t\"   \"t\"   \"c\"   \"g\"   ## BTB-262  \"g\"   \"g\"   \"c\"   \"c\"   \"g\"   ## BTB-604  \"g\"   \"g\"   \"c\"   \"c\"   \"g\"   ##  ## $lineage1_cluster7 ##          [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## BTB-1332 \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"c\"  \"g\"  \"a\"  \"t\"   \"t\"   \"c\"   \"a\"   ## BTB-1645 \"a\"  \"c\"  \"g\"  \"t\"  \"t\"  \"a\"  \"c\"  \"t\"  \"a\"  \"t\"   \"t\"   \"c\"   \"g\"   ## BTB-584  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"c\"  \"g\"  \"a\"  \"t\"   \"t\"   \"g\"   \"a\"   ## BTB-640  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"c\"  \"g\"  \"g\"  \"c\"   \"t\"   \"c\"   \"g\"   ## BTB-665  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"g\"  \"a\"  \"t\"   \"a\"   \"c\"   \"a\"   ##          [,14] ## BTB-1332 \"g\"   ## BTB-1645 \"g\"   ## BTB-584  \"g\"   ## BTB-640  \"a\"   ## BTB-665  \"g\""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"creating-xml-files-for-beast2","dir":"Articles","previous_headings":"","what":"Creating XML Files for BEAST2","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"cluster, create xml file BEAST2. general, BEAUti used create xml files BEAST2, using model mostly across clusters. TB data, package comes template xml function create_cluster_xml fill necessary information cluster. model associated xml template: Strict clock model HKY substitution model Coalescent constant population tree prior Uniform clock rate prior, user-supplied bounds Log-normal(1, 1.25) (w/ upper bound 1) frequency parameter Log-normal(1, 1.25) transition-transversion parameter HKY (kappa) Log-normal(1, 1.25) coalescent population size parameter function create xml files requires sequences (SNPs, us) cluster, name cluster, sampling dates sequences cluster, directory output xml files . function return anything, writes xml files directory specified out_dir. Messages printed xml file written.","code":"# For each lineage, write the xml files for all clusters invisible(lapply(seq_along(snp_matrices), function(lineage_index) {   # Get list of clusters for the lineage   lineage_seqs <- snp_matrices[[lineage_index]]   # Get cluster assignments data frame for the lineage   cluster_assignments_lineage <- cluster_assignments[[lineage_index]]   create_xml_files(seqs_list = lineage_seqs,                    cluster_assignments = cluster_assignments_lineage,                    out_dir = system.file(\"mcc_trees_example\", \"BEAST2\",                                          package = \"beast2tpPipeline\")) }))"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"running-beast2","dir":"Articles","previous_headings":"","what":"Running BEAST2","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"Next, run BEAST2 xml files just created. use run_beast2 function, calls command-line BEAST2 using system. may need change beast2_path argument depending version BEAST2 installed installed . parallelized code using parallel package. necessary, can speed process multiple cores available. Note work Windows, ways parallelize Windows machines. running BEAST2, cluster, log file tree file. log file logs MCMC sampling process, tree file contains posterior trees. First, quick check mixing MCMC, can make sure effective sample size (ESS) 200 parameters. can using ess_checks function, calls package tracerer. ESS low, may want consider re-running BEAST2 iterations. sure also look traceplots MCMC run, easiest Tracer.","code":"cores <- parallel::detectCores() / 2 input_xml <- list.files(system.file(\"mcc_trees_example\", \"BEAST2\",                                     package = \"beast2tpPipeline\"),                         pattern = \"\\\\.xml\", full.names = TRUE) invisible(parallel::mclapply(input_xml, run_beast2, mc.cores = cores)) beast_logs <- list.files(system.file(\"mcc_trees_example\", \"BEAST2\",                                      package = \"beast2tpPipeline\"),                          pattern = \"\\\\.log\", full.names = TRUE) invisible(sapply(beast_logs, function(log) {   ess_checks(\"BEAST2\", log, min_ess = 200) })) ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## lineage4_cluster183.log: ## ESS is too low for 2 parameters ##  ESS: 117    ESS: 162 ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"creating-maximum-clade-credibility-trees","dir":"Articles","previous_headings":"","what":"Creating Maximum Clade Credibility Trees","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"Next, create maximum clade credibility (MCC) tree posterior trees. MCC tree single tree attempts summarize posterior trees, like mean median posterior samples values real line. use get_mcctree function . get_mcctree calls command-line TreeAnnotator BEAST2 suite, may need change treeannotator_path argument depending TreeAnnotator installed. function outputs nothing, MCC trees saved specified output directory. MCC trees look like , example:  associated error bars node uncertainty tree topology, accounted TransPhylo.","code":"trees_files <- list.files(system.file(\"mcc_trees_example\", \"BEAST2\",                                       package = \"beast2tpPipeline\"),                           pattern = \".trees\", full.names = TRUE) out_dir <- system.file(\"mcc_trees_example\", \"BEAST2\", \"mcctree\",                        package = \"beast2tpPipeline\") invisible(parallel::mclapply(seq_along(trees_files), function(i) {   get_mcctree(input_treesfile = trees_files[i], output_dir = out_dir) }, mc.cores = cores)) ## Error in get(paste0(generic, \".\", class), envir = get_method_env()) :  ##   object 'type_sum.accel' not found"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"run-transphylo-on-the-mcc-trees","dir":"Articles","previous_headings":"","what":"Run TransPhylo on the MCC Trees","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"Now MCC trees, can run TransPhylo . TransPhylo package tries infer “infected ” tree, transmission tree, taking phylogenetic tree data. reality, uncertainty phylogenetic tree, TransPhylo account . use run_TransPhylo function run TransPhylo MCC trees. first read MCC trees created , make sure names match names cluster assignments data frame (BEAST2 slight renaming outputs automatically), run TransPhylo. can run TransPhylo trees , sharing couple parameters common across trees can estimated simultaneously. function outputs data frame containing sample ID probability sample infection source, .e., probability infected someone else TB. also saves TransPhylo results (resTransPhylo object output TransPhylo::infer_multittree_share_param) .rds file specified output directory. can also use ess_checks function check mixing TransPhylo run, probably useful look traceplots estimated parameters. example , using TransPhylo function first cluster.  TransPhylo also provides methods summarizing posterior trees, plotting result. example, can get “medoid” (extension median) tree plot . , phylogenetic tree plotted colors, color represents individual asterisks represent transmission events. TransPhylo object called ctree, combined phylogenetic/transmission tree (“colored tree”).  also “consensus” tree, built combining clades occurring least fraction posterior samples. tree necessarily tree posterior samples. can plotted plot. TransPhylo object called ttree, transmission tree.","code":"# Read the trees and manipulate the names to make sure they match # the names in cluster_assignments mcc_trees_files <- list.files(system.file(\"mcc_trees_example\",                                           \"BEAST2\", \"mcctree\",                                           package = \"beast2tpPipeline\"),                               pattern = \".tree\", full.names = TRUE) mcc_trees <- lapply(mcc_trees_files, ape::read.nexus) names(mcc_trees) <- gsub(\".nexus\", \"\", basename(mcc_trees_files)) names(mcc_trees) <- gsub(\".*-\", \"\", names(mcc_trees)) # Want to run trees from all lineages together, so paste the cluster # assignments list of dataframes into one dataframe all_cluster_assignments <- do.call(rbind, cluster_assignments) # Run TransPhylo on the MCC trees prob_source <- run_TransPhylo(mcc_trees,                               type = \"mcctrees\",                               cluster_dict = all_cluster_assignments,                               out_dir = system.file(\"mcc_trees_example\",                                                     \"TransPhylo\",                                                     package = \"beast2tpPipeline\"),                               w.shape = 10,                               w.scale = 0.1,                               prior_pi_a = 1,                               prior_pi_b = 19,                               share = c(\"neg\", \"off.r\"),                               startNeg = 1.48,                               mcmcIterations = 100000) transphylo_res <- readRDS(transphylo_res_file) TransPhylo::plotTraces(transphylo_res[[1]]) medoid <- TransPhylo::medTTree(transphylo_res[[1]]) TransPhylo::plotCTree(medoid) cons <- TransPhylo::consTTree(transphylo_res[[1]]) plot(cons)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"regression-with-transphylo-results","dir":"Articles","previous_headings":"","what":"Regression with TransPhylo Results","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"Finally, can kind regression probabilities assigned TransPhylo. run linear regression probabilities response variable HIV status predictor. use regression function . can add covariates adding columns cleaned_data data frame. regression function automatically remove rows missing values. Alternatively, probability threshold can set mark individuals infectors non-infectors, logistic regression may run. done setting method argument regression \"logistic\" specifying threshold.","code":"# Get dataframe with covariates for regression cleaned_data <- metadata[, c(\"SampleID\", \"hivfinal_new\")] cleaned_data <- cleaned_data[complete.cases(cleaned_data), ] cleaned_data$hivfinal_new <- as.factor(cleaned_data$hivfinal_new - 1) # Run a linear model with the probabilities from TransPhylo mdl <- regression(method = \"linear\",                   cleaned_data = cleaned_data,                   prob_source = prob_source) summary(mdl) # Get dataframe with covariates for regression, add age and gender cleaned_data <- metadata[, c(\"SampleID\", \"hivfinal_new\", \"agenew\", \"genderf1\")] cleaned_data <- cleaned_data[complete.cases(cleaned_data), ] cleaned_data$hivfinal_new <- as.factor(cleaned_data$hivfinal_new - 1) cleaned_data$genderf1 <- factor(cleaned_data$genderf1,                                 levels = c(1, 2),                                 labels = c(\"M\", \"F\")) # Run a linear model with the probabilities from TransPhylo mdl <- regression(method = \"linear\",                   cleaned_data = cleaned_data,                   prob_source = prob_source) summary(mdl) ##  ## Call: ## lm(formula = prob_source ~ ., data = cleaned_data) ##  ## Residuals: ##      Min       1Q   Median       3Q      Max  ## -0.26801 -0.17625 -0.14314  0.00812  0.87396  ##  ## Coefficients: ##                Estimate Std. Error t value Pr(>|t|)    ## (Intercept)    0.251241   0.077408   3.246  0.00134 ** ## hivfinal_new1  0.019518   0.041655   0.469  0.63981    ## agenew        -0.002502   0.001745  -1.434  0.15291    ## genderf1F     -0.019601   0.042283  -0.464  0.64339    ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 0.3058 on 236 degrees of freedom ## Multiple R-squared:  0.01246,    Adjusted R-squared:  -9.254e-05  ## F-statistic: 0.9926 on 3 and 236 DF,  p-value: 0.397 # Run a logistic model with the probabilities from TransPhylo # Set the probability threshold to 0.5, where prob >= 0.5 is # considered an infector mdl_logistic <- regression(method = \"logistic\",                            cleaned_data = cleaned_data,                            prob_source = prob_source,                            prob_cutoff = 0.5) summary(mdl_logistic)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"exploration-of-the-pipeline","dir":"Articles","previous_headings":"","what":"Exploration of the Pipeline","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"package makes convenient change parts pipeline explore impact changes results. example, suppose want change sampling fraction prior TransPhylo, get new results, linear regression results, compare old results. Now updated probabilities, can redo linear (logistic) regression new probabilities.","code":"# Run TransPhylo on the MCC trees with a new sampling fraction prior # Using same MCC trees we have already read in prob_source <- run_TransPhylo(mcc_trees,                               type = \"mcctrees\",                               cluster_dict = all_cluster_assignments,                               out_dir = system.file(\"mcc_trees_example\",                                                     \"TransPhylo\",                                                     package = \"beast2tpPipeline\"),                               output_name = \"tp_res_changed_sampling_frac\",                               w.shape = 10,                               w.scale = 0.1,                               prior_pi_a = 26,                               prior_pi_b = 74,                               share = c(\"neg\", \"off.r\"),                               startNeg = 1.48,                               mcmcIterations = 100000)  # Check mixing again transphylo_res <- system.file(\"mcc_trees_example\", \"TransPhylo\",                               \"tp_res_changed_sampling_frac.rds\",                               package = \"beast2tpPipeline\") ess_checks(\"TransPhylo\", transphylo_res, min_ess = 10) mdl_new <- regression(method = \"linear\",                       cleaned_data = cleaned_data,                       prob_source = prob_source) summary(mdl_new) ##  ## Call: ## lm(formula = prob_source ~ ., data = cleaned_data) ##  ## Residuals: ##      Min       1Q   Median       3Q      Max  ## -0.26801 -0.17625 -0.14314  0.00812  0.87396  ##  ## Coefficients: ##                Estimate Std. Error t value Pr(>|t|)    ## (Intercept)    0.251241   0.077408   3.246  0.00134 ** ## hivfinal_new1  0.019518   0.041655   0.469  0.63981    ## agenew        -0.002502   0.001745  -1.434  0.15291    ## genderf1F     -0.019601   0.042283  -0.464  0.64339    ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 0.3058 on 236 degrees of freedom ## Multiple R-squared:  0.01246,    Adjusted R-squared:  -9.254e-05  ## F-statistic: 0.9926 on 3 and 236 DF,  p-value: 0.397"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jessalyn Sebastian. Author, maintainer.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Sebastian J (2024). beast2tpPipeline: BEAST2 TransPhylo Regression Pipeline. R package version 0.0.0.9000, https://jessalynnsebastian.github.io/beast2tpPipeline/.","code":"@Manual{,   title = {beast2tpPipeline: BEAST2 to TransPhylo to Regression Pipeline},   author = {Jessalyn Sebastian},   year = {2024},   note = {R package version 0.0.0.9000},   url = {https://jessalynnsebastian.github.io/beast2tpPipeline/}, }"},{"path":[]},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"BEAST2 to TransPhylo to Regression Pipeline","text":"package created work data Kopanyo study, namely fasta files TB sequences associated metadata. defines clear pipeline fasta files sequences associated metadata, creating SNP clusters, running BEAST2, running TransPhylo, regression results. Using genetic data identify transmission risk factors: Statistical assessment application tuberculosis transmission, Goldstein et al. show pipeline biased; BEAST2-TransPhylo pipeline low sensitivity identifying infection sources biases regression coefficients toward zero. package built facilitate exploration qualities pipeline. package built step pipeline associated function. steps functions : Assigning SNP clusters: assign_snp_clusters takes set sequences metadata, assigns sequences SNP clusters. Creating BEAST2 clusters: create_BEAST2_clusters takes SNP clusters separates sequence data cluster, keeping SNPs desired. Creating XML files BEAST2: create_cluster_xml takes SNP data creates XML file BEAST2 run. Running BEAST2: run_beast2 runs BEAST2 XML file. take DNA sequences infer timed phylogenetic tree, tells us ancestry pathogen. Getting MCC trees: get_mcctree takes posterior trees BEAST2 creates maximum clade credibility tree - summary tree, like mean median. (Alternatively, Getting Sample Posterior Trees: sample_BEAST2_trees takes posterior trees BEAST2 subsamples specified number .) Running TransPhylo MCC trees: run_TransPhylo runs TransPhylo MCC trees, sharing parameters can simultaneously estimated. take timed phylogeny use try infer -infected-. (Alternatively, can use run_TransPhylo run TransPhylo subsample BEAST2 trees, without parameter sharing.) Running regression TransPhylo results: regression runs linear logistic regression using TransPhylo results. draw inference relationship covariates individual transmission probabilities.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"BEAST2 to TransPhylo to Regression Pipeline","text":"Install beast2tpPipeline package GitHub: dependencies automatically downloaded. , load package: also need BEAST2 installed computer. can download . use package manager like homebrew, can install BEAST2 brew install beast2 terminal. install suite programs, including BEAST2, BEAUti, TreeAnnotator. probably also want install Tracer look traceplots diagnostics BEAST2 runs. can download Tracer .","code":"devtools::install_github(\"jessalynnsebastian/beast2tpPipeline\", build_vignettes = TRUE) library(beast2tpPipeline)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/assign_snp_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign SNP Clusters to Samples — assign_snp_clusters","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"function assigns SNP clusters samples based SNP distance threshold, , alternatively, based transmission clusters Stimson et al. paper, Beyond SNP Threshold: Identifying Outbreak Clusters Using Inferred Transmissions.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/assign_snp_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"","code":"assign_snp_clusters(   seqs = NULL,   collectdts,   snp_matrix = NULL,   threshold = 5,   clockrate = -1,   transm_rate = -1 )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/assign_snp_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"seqs Matrices containing sequences. collectdts numeric vector collection dates, names corresponding rownames seqs matrix. snp_matrix SNP distances previously computed, include argument avoid re-computing. threshold numeric value SNP threshold, transmission threshold using transmission clusters (see transcluster info). clockrate numeric value clock rate using transmission clusters. transm_rate numeric value transmission rate using transmission clusters.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/assign_snp_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"data frame containing sample ID, cluster name, collection date sample.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_BEAST2_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"Using SNP cluster information DNA sequences, separate sequences separate DNAbin objcts cluster. desired, keep SNPs.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_BEAST2_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"","code":"create_BEAST2_clusters(   seqs,   cluster_assignments,   min_cluster_size = 4,   min_varsites = 8,   snps_only = TRUE,   constant_sites = \"\",   cluster_dictionary_file = NULL,   fasta_dir = NULL )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_BEAST2_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"seqs matrix DNA sequences, rownames correspond sample IDs, ape::DNAbin object. cluster_assignments data frame cluster assignments, including least sample_id cluster_name, output assign_snp_clusters. Must also include collectdt writing cluster dictionary. min_cluster_size number samples required keep cluster. cluster small, discard . min_varsites number variable sites required keep cluster. enough variable sites, discard cluster. snps_only TRUE, keep SNPs output DNAbin objects. constant_sites string constant sites add beginning sequence. necessary BEAST2 input using SNPs. Defaults empty string. cluster_dictionary_file Optionally, file path write cluster dictionary , containing cluster names, sizes, varsites. fasta_dir Optionally, directory write FASTA files cluster. FASTA files automatically named cluster names.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_BEAST2_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"named list matrices containing SNPs.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_xml_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Create BEAST2 XML Files from a Template — create_xml_files","title":"Create BEAST2 XML Files from a Template — create_xml_files","text":"Use template XML file create new XML files BEAST2 input. function can replace sequences, sampling dates, mcmc iterations, frequency storing trees, , uniform clock rate, minimum maximum clock rates. designed just used provided template file, though theoretically used others. template file written tuberculosis data. contains adjustment ascertainment bias due SNPs, Gamma site model, HKY substitution model, strict clock, Coalescent constant population model, uniform clock rate prior (min/max editable), lognormal(1, 1.25) freqParameter, kappa, popsize priors. template xml contains placeholders: SNP_FILE_NAME_HERE name SNP file ALIGNMENT_INFORMATION_HERE sequence information DATE_INFORMATION_HERE sampling dates CLOCKRATE_MINIMUM_HERE minimum uniform clock rate CLOCKRATE_MAXIMUM_HERE maximum uniform clock rate CLOCKRATE_INITIAL_HERE initial clock rate MCMC_ITERATIONS_HERE number MCMC iterations STORE_EVERY_HERE frequency storing trees","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_xml_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create BEAST2 XML Files from a Template — create_xml_files","text":"","code":"create_xml_files(   path_to_template = system.file(\"xml_template/0_xml_template.xml\", package =     \"beast2tpPipeline\"),   seqs_list,   cluster_assignments,   mcmc_iterations = 2e+07,   store_every = 5000,   min_clockrate = 10^(-8),   max_clockrate = 5 * 10^(-7),   init_clockrate = 10 * min_clockrate,   whole_genome_length = 4.2 * 10^6,   out_dir )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_xml_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create BEAST2 XML Files from a Template — create_xml_files","text":"path_to_template path template XML file. seqs_list list matrices DNA sequences (SNPs), rownames correspond sample IDs. cluster_assignments data frame cluster assignments, including sample_id, cluster_name, collectdt, output assign_snp_clusters. sample IDs seqs matrices must present data frame. mcmc_iterations number MCMC iterations run. store_every frequency storing trees. min_clockrate minimum clock rate uniform clock rate prior. Defaults tuberculosis genome clock rate. adjust SNPs . max_clockrate maximum clock rate uniform clock rate prior. Defaults tuberculosis genome clock rate. init_clockrate initial clock rate clock rate. whole_genome_length length whole genome. Used adjust clock rate SNPs. Defaults TB length. out_dir directory write output XML file. Files automatically named FASTA names.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/ess_checks.html","id":null,"dir":"Reference","previous_headings":"","what":"Use Effective Sample Size to Check Mixing — ess_checks","title":"Use Effective Sample Size to Check Mixing — ess_checks","text":"BEAST2 run TransPhylo run, pull effective sample size estimated parameters. Check threshold.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/ess_checks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use Effective Sample Size to Check Mixing — ess_checks","text":"","code":"ess_checks(   program = c(\"BEAST2\", \"TransPhylo\"),   path_to_mcmc_log,   burn_in_fraction = 0.1,   sample_interval = 5000,   min_ess )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/ess_checks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use Effective Sample Size to Check Mixing — ess_checks","text":"program Character string. Either \"BEAST2\" \"TransPhylo\". path_to_mcmc_log Character string. Path MCMC log file. burn_in_fraction Numeric. Fraction MCMC chain discard burn-. sample_interval Numeric. Interval samples taken. min_ess Numeric. Minimum effective sample size consider acceptable.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_mcctree.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","title":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","text":"Run TreeAnnotator get maximum clade credibility tree BEAST2 tree file.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_mcctree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","text":"","code":"get_mcctree(   input_treesfile,   output_dir,   beast_iterations = 2e+07,   burnin_fraction = 1/2,   heights = \"CA\",   treeannotator_path = \"/Applications/\\\"BEAST 2.7.7\\\"/bin/treeannotator\" )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_mcctree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","text":"input_treesfile Character string. Path BEAST2 .trees file. output_dir Character string. Path desired output directory MCC tree nexus file. beast_iterations Numeric. Number iterations BEAST2 run. burnin_fraction Numeric. Fraction MCMC chain discard burn-. heights Character string. Node heights tree. Beware using anything common ancestor, get weird trees work TransPhylo. treeannotator_path Character string. Path TreeAnnotator executable.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Linear or Logistic Regression with TransPhylo Results — regression","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"function takes probability estimates TransPhylo runs linear regression , logistic regression probability cutoff label individual infection source specified.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"","code":"regression(   method = c(\"logistic\", \"linear\"),   cleaned_data,   prob_source,   prob_cutoff = NULL )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"method character string specifying type regression run. Can \"linear\" \"logistic\". cleaned_data data frame containing covariates use regression. Must contain column \"SampleID\" sample IDs. prob_source data frame probabilities output TransPhylo columns SampleID prob_source (output run_TransPhylo), indicating probability sample infection source. prob_cutoff numeric specifying probability cutoff use logistic regression. NULL, logistic regression run.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"lm glm object.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_TransPhylo.html","id":null,"dir":"Reference","previous_headings":"","what":"Run TransPhylo on a Set of Trees — run_TransPhylo","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"wrapper TransPhylo::infer_multittree_share_param. Can use run TransPhylo set trees, either MCC trees parameter sharing, sample posterior BEAST2 trees without parameter sharing (.e., sample BEAST2 posterior trees single cluster, incorporate phylogenetic uncertainty).","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_TransPhylo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"","code":"run_TransPhylo(   trees,   cluster_name = NULL,   type = c(\"mcctrees\", \"trees_sample\"),   cluster_dict,   out_dir = \"TransPhylo\",   output_name = \"tp_res\",   ... )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_TransPhylo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"trees ape multiPhylo object containing trees analyzed. type \"mcctrees\", MCC trees clusters, names trees need match names trees cluster dictionary. type \"trees_sample\", sample posterior BEAST2 trees single cluster, cluster name provided argument. cluster_name type \"trees_sample\", name cluster trees analyzed. match cluster name cluster dictionary. type \"mcctrees\", argument ignored. type character string specifying type trees analyzed. Can \"mcctrees\" \"trees_sample\". \"mcctrees\", function run TransPhylo MCC trees clusters. \"trees_sample\", function run TransPhylo sample posterior BEAST2 trees single cluster. cluster_dict data frame containing sample_id, cluster_name, collectdt sequence, output assign_snp_clusters. out_dir character string specifying directory TransPhylo results saved. output_name character string specifying name output file. ... Additional arguments passed TransPhylo::infer_multittree_share_param.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_TransPhylo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"data frame containing probability sample infection source.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_beast2.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Command-Line BEAST2 — run_beast2","title":"Run Command-Line BEAST2 — run_beast2","text":"Run BEAST2 XML file. Tree files, log files, etc. written directory XML file.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_beast2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Command-Line BEAST2 — run_beast2","text":"","code":"run_beast2(   input_xml_path,   beast2_path = \"/Applications/\\\"BEAST 2.7.7\\\"/bin/beast\" )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_beast2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Command-Line BEAST2 — run_beast2","text":"input_xml_path Character string. Path BEAST2 XML file. beast2_path Character string. Path BEAST2 executable.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/sample_BEAST2_trees.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample BEAST2 Trees — sample_BEAST2_trees","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"function takes BEAST2 posterior trees samples subset , making sure keep tree names.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/sample_BEAST2_trees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"","code":"sample_BEAST2_trees(trees_file, n_trees, seed = NULL, out_dir = NULL)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/sample_BEAST2_trees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"trees_file string path BEAST2 posterior trees file. n_trees integer number trees sample. seed Optionally, seed use tree sampling. out_dir Optionally, string directory write sampled trees .","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/sample_BEAST2_trees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"ape multiPhylo object containing tree sample.","code":""}]
