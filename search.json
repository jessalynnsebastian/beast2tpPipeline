[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 beast2tpPipeline authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/mcc_tree_pipeline.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"vignette walk process using beast2tpPipeline package create SNP clusters set fasta files, create xml files cluster, run BEAST2, run TransPhylo BEAST2 results, kind regression probabilities assigned TransPhylo. running BEAST2, set posterior trees cluster. package can two things: Create maximum clade credibility (MCC) tree posterior trees, run TransPhylo multitree MCC trees, sharing parameters can simultaneously estimated. MCC tree single tree attempts summarize posterior trees, like mean median posterior samples values real line. method take one tree summarizes posterior trees cluster, run TransPhylo true phylogenetic trees. Subsample number trees BEAST2 posterior tree samples cluster, run TransPhylo sample trees cluster, rather one summary tree. advantage accounting phylogenetic uncertainty BEAST2 trees, rather assuming one tree truth. However, computationally expensive: instead one TransPhylo run clusters, run TransPhylo cluster separately, time decently-sized set trees. run computing cluster. Additionally, via method, parameter sharing possible. vignette, use package (1). First, load package library.","code":"library(beast2tpPipeline)"},{"path":"/articles/mcc_tree_pipeline.html","id":"data-for-this-example","dir":"Articles","previous_headings":"","what":"Data for this Example","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"package comes data collected Kopanyo study, tuberculosis (TB) samples collected two regions Botswana, country high prevalence TB human immodeficiency virus (HIV). Read study . data contain 4 fasta files, one lineage TB. fasta file contains aligned TB sequences study participants. also metadata available samples, including things like HIV status, age, gender, sample collection date, handful variables. Suppose interested using TB sequences draw inference whether HIV makes individual likely transmit TB someone else.","code":""},{"path":"/articles/mcc_tree_pipeline.html","id":"creating-single-nucleotide-polymorphism-snp-clusters","dir":"Articles","previous_headings":"","what":"Creating Single Nucleotide Polymorphism (SNP) Clusters","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"First, read fasta files metadata R. can take peek data: Notice 1426 sequences corresponding metadata. computationally intensive run BEAST2 sequences simultaneously. Instead, create clusters similar sequences run BEAST2 cluster separately. create clusters, use SNP thresholding. SNPs single nucleotide polymorphisms, single base pair differences sequences. can use differences group sequences clusters likely closely related . use transcluster package . transcluster package developed alongside paper Beyond SNP Threshold: Identifying Outbreak Clusters Using Inferred Transmissions. built handle plain SNP thresholding create clusters, also clustering based likely transmissions. use former, simpler commonly used, latter still available function. assign sequences clusters based SNPs, use assign_snp_clusters, wrapper around transcluster functions. Computing distance matrix large clusters can take time, already distance matrix saved, can pass assign_snp_clusters dist_matrix argument. Next, create actual BEAST2 clusters using create_BEAST2_clusters function. take sequences, split separate objects, keep SNPs (sites across sequences matter BEAST2), write fasta files used BEAUti create_cluster_xml. discard clusters fewer 4 sequences, clusters fewer 8 SNPs. also add constant sites sequences, deal ascertainment bias BEAST2 since keeping SNPs. cluster, create xml file BEAST2. general, BEAUti used create xml files BEAST2, using model mostly across clusters. TB data, package comes template xml function create_cluster_xml fill necessary information cluster. model associated xml template: Strict clock model HKY substitution model Coalescent constant population tree prior Uniform clock rate prior, user-supplied bounds (Default) Log-normal(1, 1.25) (w/ upper bound 1) frequency parameter (Default) Log-normal(1, 1.25) transition-transversion parameter HKY (kappa) (Default) Log-normal(1, 1.25) coalescent population size parameter","code":"fasta_files <- list.files(system.file(\"kopanyo\", package = \"beast2tpPipeline\"),                           pattern = \".fasta\", full.names = TRUE) tb_sequences <- lapply(fasta_files, ape::read.dna, format = \"fasta\",                        as.character = TRUE)  metadata <- list.files(system.file(\"kopanyo\", package = \"beast2tpPipeline\"),                        pattern = \".csv\", full.names = TRUE) metadata <- read.csv(metadata) head(metadata) ##   SampleID Lineage genderf1 agenew hivfinal_new gMixture  collectdt smokef1 ## 1 BTB-1139       1        1     52            1        0 2014-07-30       1 ## 2 BTB-1146       1        1     43            1        1 2014-08-05       1 ## 3 BTB-1705       1        1     70            2        1 2015-06-10       1 ## 4  BTB-175       1        2     19            1        1 2013-01-16       2 ## 5 BTB-1774       1        1     38            1        1 2015-07-30       2 ## 6 BTB-1894       1        1     15           NA        1 2015-10-16       2 ##   tb_everf3 alcohol_excess Lineage_detailed ## 1         2              2            1.1.2 ## 2         2              1            1.1.2 ## 3         1              2            1.1.2 ## 4         1              2            1.1.2 ## 5         1              2            1.1.2 ## 6         1              2            1.1.2 dim(metadata) ## [1] 1426   11 # Get collection dates by lineage collectdts <- split(metadata, metadata$Lineage) # Create named vectors of dates, as required by the function collectdts <- lapply(collectdts, function(meta) {   dates <- meta$collectdt   names(dates) <- meta$SampleID   dates })  # TODO: REMOVE THIS WHEN TESTING IS DONE. tb_sequences <- tb_sequences[1:3] collectdts <- collectdts[1:3]  # Apply the function to each lineage of sequences cluster_assignments <- mapply(assign_snp_clusters,                               seqs = tb_sequences,                               collectdts = collectdts,                               threshold = 5,                               SIMPLIFY = FALSE) ## Creating SNP-based clusters ## Creating SNP-based clusters ## Creating SNP-based clusters # Rename clusters to include lineage cluster_assignments <- lapply(seq_along(cluster_assignments), function(i) {   cluster_assignments[[i]]$cluster_name <- paste0(\"lineage\", i, \"_\", cluster_assignments[[i]]$cluster_name)   cluster_assignments[[i]] })  # Take a look at the cluster assignments lapply(cluster_assignments, head) ## [[1]] ##   sample_id      cluster_name  collectdt ## 1  BTB-1023 lineage1_cluster1 2014-05-13 ## 2  BTB-1058 lineage1_cluster2 2014-06-04 ## 3  BTB-1088 lineage1_cluster3 2014-06-25 ## 4    BTB-10 lineage1_cluster4 2012-09-10 ## 5  BTB-1133 lineage1_cluster5 2014-07-25 ## 6  BTB-1139 lineage1_cluster6 2014-07-30 ##  ## [[2]] ##   sample_id      cluster_name  collectdt ## 1  BTB-1000 lineage2_cluster1 2014-04-28 ## 2  BTB-1014 lineage2_cluster2 2014-05-07 ## 3  BTB-1025 lineage2_cluster3 2014-05-13 ## 4  BTB-1115 lineage2_cluster4 2014-07-16 ## 5  BTB-1123 lineage2_cluster5 2014-07-16 ## 6  BTB-1160 lineage2_cluster6 2014-08-12 ##  ## [[3]] ##   sample_id      cluster_name  collectdt ## 1   BTB-119 lineage3_cluster1 2012-12-03 ## 2  BTB-1259 lineage3_cluster2 2014-09-25 ## 3  BTB-1344 lineage3_cluster3 2014-11-11 ## 4  BTB-1410 lineage3_cluster1 2014-12-10 ## 5   BTB-155 lineage3_cluster1 2013-01-07 ## 6  BTB-1698 lineage3_cluster1 2015-06-08 # For each lineage, use the cluster assignments to put the sequences # into clusters snp_matrices <- lapply(seq_along(tb_sequences), function(lineage_index) {   # Note that the TB sequences are in format matrix   create_BEAST2_clusters(seqs = tb_sequences[[lineage_index]],                          # and snp_clusters is a named vector of cluster assignments,                          # where the names are the sample ids                          snp_clusters = setNames(cluster_assignments[[lineage_index]]$cluster_name,                                                  cluster_assignments[[lineage_index]]$sample_id),                          min_cluster_size = 4,                          min_varsites = 8,                          snps_only = TRUE,                          constant_sites = \"acgt\") }) # Now we have a list of 4 lineages, each containing a list of clusters # (data frames) within that lineage # Now that we won't be working with the fasta files themselves anymore, # let's turn this list of lists into a list, and let's turn the list of # cluster assignments into a data frame snp_matrices <- unlist(snp_matrices, recursive = FALSE) cluster_assignments <- do.call(rbind, cluster_assignments) # For each cluster, create an xml file for BEAST2 invisible(lapply(names(snp_matrices), function(cluster_name) {   create_cluster_xml(seqs = snp_matrices[[cluster_name]],                      cluster_name = cluster_name,                      sampling_dates = setNames(cluster_assignments$collectdt[cluster_assignments$cluster_name == cluster_name],                                                cluster_assignments$sample_id[cluster_assignments$cluster_name == cluster_name]),                      out_dir = system.file(\"mcc_trees_example\", \"BEAST2\",                                            package = \"beast2tpPipeline\")) })) # TODO: make sure parallelizing works on windows cores <- parallel::detectCores() / 2 input_xml <- list.files(system.file(\"mcc_trees_example\", \"BEAST2\",                                     package = \"beast2tpPipeline\"),                         pattern = \"\\\\.xml\", full.names = TRUE) invisible(parallel::mclapply(input_xml, run_beast2, mc.cores = cores)) beast_logs <- list.files(system.file(\"mcc_trees_example\", \"BEAST2\",                                      package = \"beast2tpPipeline\"),                          pattern = \"\\\\.log\", full.names = TRUE) invisible(sapply(beast_logs, function(log) {   ess_checks(\"BEAST2\", log, min_ess = 200) })) trees_files <- list.files(system.file(\"mcc_trees_example\", \"BEAST2\",                                       package = \"beast2tpPipeline\"),                           pattern = \".trees\", full.names = TRUE) out_dir <- system.file(\"mcc_trees_example\", \"BEAST2\", \"mcctree\",                        package = \"beast2tpPipeline\") invisible(parallel::mclapply(seq_along(trees_files), function(i) {   get_mcctree(input_treesfile = trees_files[i], output_dir = out_dir) }, mc.cores = cores)) # Read the trees and manipulate the names to make sure they match # the names in cluster_assignments mcc_trees_files <- list.files(system.file(\"mcc_trees_example\",                                           \"BEAST2\", \"mcctree\",                                           package = \"beast2tpPipeline\"),                               pattern = \".tree\", full.names = TRUE) mcc_trees <- lapply(mcc_trees_files, ape::read.nexus) names(mcc_trees) <- gsub(\".nexus\", \"\", basename(mcc_trees_files)) names(mcc_trees) <- gsub(\".*-\", \"\", names(mcc_trees)) # Run TransPhylo on the MCC trees prob_source <- run_TransPhylo(mcc_trees,                               type = \"mcctrees\",                               cluster_dict = cluster_assignments,                               out_dir = system.file(\"mcc_trees_example\",                                                     \"TransPhylo\",                                                     package = \"beast2tpPipeline\"),                               w.shape = 10,                               w.scale = 0.1,                               prior_pi_a = 1,                               prior_pi_b = 19,                               share = c(\"neg\", \"off.r\"),                               startNeg = 1.48,                               mcmcIterations = 100) prob_source <- readRDS(system.file(\"mcc_trees_example\", \"TransPhylo\",                                    \"tp_res_prob_source.rds\",                                    package = \"beast2tpPipeline\")) # Get dataframe with covariates for regression cleaned_data <- metadata[, c(\"SampleID\", \"hivfinal_new\")] cleaned_data <- cleaned_data[complete.cases(cleaned_data), ] cleaned_data$hivfinal_new <- as.factor(cleaned_data$hivfinal_new - 1) # Run a linear model with the probabilities from TransPhylo mdl <- regression(method = \"linear\",                   cleaned_data = cleaned_data,                   prob_source = prob_source) summary(mdl)"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jessalyn Sebastian. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Sebastian J (2024). beast2tpPipeline: BEAST2 TransPhylo Regression Pipeline. R package version 0.0.0.9000, https://jessalynnsebastian.github.io/beast2tpPipeline/.","code":"@Manual{,   title = {beast2tpPipeline: BEAST2 to TransPhylo to Regression Pipeline},   author = {Jessalyn Sebastian},   year = {2024},   note = {R package version 0.0.0.9000},   url = {https://jessalynnsebastian.github.io/beast2tpPipeline/}, }"},{"path":[]},{"path":"/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"BEAST2 to TransPhylo to Regression Pipeline","text":"package created work data Kopanyo study, namely fasta files TB sequences associated metadata. package built step pipeline associated function. steps functions : Assigning SNP clusters: assign_snp_clusters takes set sequences metadata, assigns sequences SNP clusters. Creating BEAST2 clusters: create_BEAST2_clusters takes SNP clusters separates sequence data cluster, keeping SNPs. Creating XML files BEAST2: create_cluster_xml takes SNP data creates XML file BEAST2 run. Running BEAST2: run_beast2 runs BEAST2 XML file. take DNA sequences infer timed phylogenetic tree, tells us ancestry pathogen. Getting MCC trees: get_mcctree takes posterior trees BEAST2 creates maximum clade credibility tree - summary tree, like mean median. (Alternatively, Getting Sample Posterior Trees: sample_BEAST2_trees takes posterior trees BEAST2 subsamples specified number .) Running TransPhylo MCC trees: run_TransPhylo runs TransPhylo MCC trees, sharing parameters can simultaneously estimated. take timed phylogeny use try infer -infected-. (Alternatively, can use run_TransPhylo run TransPhylo subsample BEAST2 trees, without parameter sharing.) Running regression TransPhylo results: regression runs linear logistic regression using TransPhylo results. draw inference relationship covariates individual transmission probabilities.","code":""},{"path":"/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"BEAST2 to TransPhylo to Regression Pipeline","text":"use package, need dependencies installed. can install following code: also need BEAST2 installed computer. can download . use package manager like homebrew, can install BEAST2 brew install beast2 terminal. install suite programs, including BEAST2, BEAUti, TreeAnnotator. probably also want install Tracer look traceplots diagnostics BEAST2 runs. can download Tracer . Next, install beast2tpPipeline package GitHub: , load package:","code":"install.packages(c(\"ape\", \"TransPhylo\", \"coda\", \"tracerer\", \"lubridate\", \"tidyverse\")) remotes::install_github(\"JamesStimson/transcluster\", build_vignettes = TRUE) devtools::install_github(\"jessalynnsebastian/beast2tpPipeline\", build_vignettes = TRUE) library(beast2tpPipeline)"},{"path":"/reference/assign_snp_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign SNP Clusters to Samples — assign_snp_clusters","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"function assigns SNP clusters samples based SNP distance threshold, , alternatively, based transmission clusters Stimson et al. paper, Beyond SNP Threshold: Identifying Outbreak Clusters Using Inferred Transmissions.","code":""},{"path":"/reference/assign_snp_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"","code":"assign_snp_clusters(   seqs,   collectdts,   snp_matrix = NULL,   threshold = 5,   clockrate = -1,   transm_rate = -1 )"},{"path":"/reference/assign_snp_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"seqs Matrices containing sequences. collectdts numeric vector collection dates, names corresponding rownames seqs matrix. snp_matrix SNP distances previously computed, include argument avoid re-computing. threshold numeric value SNP threshold, transmission threshold using transmission clusters (see transcluster info). clockrate numeric value clock rate using transmission clusters. transm_rate numeric value transmission rate using transmission clusters.","code":""},{"path":"/reference/assign_snp_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"data frame containing sample ID, cluster name, collection date sample.","code":""},{"path":"/reference/create_BEAST2_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"Using SNP cluster information DNA sequences, separate sequences separate DNAbin objcts cluster. desired, keep SNPs.","code":""},{"path":"/reference/create_BEAST2_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"","code":"create_BEAST2_clusters(   seqs,   snp_clusters,   collectdts = NULL,   min_cluster_size = 4,   min_varsites = 8,   snps_only = TRUE,   constant_sites = \"\",   cluster_dictionary_file = NULL,   fasta_dir = NULL )"},{"path":"/reference/create_BEAST2_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"seqs matrix DNA sequences, rownames correspond sample IDs, ape::DNAbin object. snp_clusters named vector SNP cluster assignments, names correspond sample IDs. collectdts named vector collection dates, names correspond sample IDs. Dates format \"YYYY-MM-DD\" decimal format. .character = TRUE). min_cluster_size number samples required keep cluster. cluster small, discard . min_varsites number variable sites required keep cluster. enough variable sites, discard cluster. snps_only TRUE, keep SNPs output DNAbin objects. constant_sites string constant sites add beginning sequence. necessary BEAST2 input using SNPs. Defaults empty string. cluster_dictionary_file Optionally, file path write cluster dictionary , containing cluster names, sizes, varsites. fasta_dir Optionally, directory write FASTA files cluster. FASTA files automatically named cluster names.","code":""},{"path":"/reference/create_BEAST2_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"named list matrices containing SNPs.","code":""},{"path":"/reference/create_cluster_xml.html","id":null,"dir":"Reference","previous_headings":"","what":"Create BEAST2 XML File — create_cluster_xml","title":"Create BEAST2 XML File — create_cluster_xml","text":"Use template XML file create new XML files BEAST2 input. function can replace sequences, sampling dates, mcmc iterations, frequency storing trees, , uniform clock rate, minimum maximum clock rates. designed just used provided template file, though theoretically used others. template file written tuberculosis data. contains adjustment ascertainment bias due SNPs, Gamma site model, HKY substitution model, strict clock, Coalescent constant population model, uniform clock rate prior (min/max editable), lognormal(1, 1.25) freqParameter, kappa, popsize priors. template xml contains placeholders: SNP_FILE_NAME_HERE name SNP file ALIGNMENT_INFORMATION_HERE sequence information DATE_INFORMATION_HERE sampling dates CLOCKRATE_MINIMUM_HERE minimum uniform clock rate CLOCKRATE_MAXIMUM_HERE maximum uniform clock rate CLOCKRATE_INITIAL_HERE initial clock rate MCMC_ITERATIONS_HERE number MCMC iterations STORE_EVERY_HERE frequency storing trees","code":""},{"path":"/reference/create_cluster_xml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create BEAST2 XML File — create_cluster_xml","text":"","code":"create_cluster_xml(   path_to_template = system.file(\"xml_template/0_xml_template.xml\", package =     \"beast2tpPipeline\"),   seqs,   cluster_name,   sampling_dates,   mcmc_iterations = 1e+07,   store_every = 5000,   min_clockrate = 10^(-8),   max_clockrate = 5 * 10^(-7),   init_clockrate = 10 * min_clockrate,   whole_genome_length = 4.2 * 10^6,   out_dir )"},{"path":"/reference/create_cluster_xml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create BEAST2 XML File — create_cluster_xml","text":"path_to_template path template XML file. seqs matrix DNA sequences (SNPs), rownames correspond sample IDs, ape::DNAbin object. cluster_name name cluster. sampling_dates named vector sampling dates, names corresponding sample IDs. Dates either decimal years format \"YYYY-MM-DD\". mcmc_iterations number MCMC iterations run. store_every frequency storing trees. min_clockrate minimum clock rate uniform clock rate prior. Defaults tuberculosis genome clock rate. adjust SNPs . max_clockrate maximum clock rate uniform clock rate prior. Defaults tuberculosis genome clock rate. init_clockrate initial clock rate clock rate. whole_genome_length length whole genome. Used adjust clock rate SNPs. Defaults TB length. out_dir directory write output XML file. Files automatically named FASTA names.","code":""},{"path":"/reference/ess_checks.html","id":null,"dir":"Reference","previous_headings":"","what":"Use Effective Sample Size to Check Mixing — ess_checks","title":"Use Effective Sample Size to Check Mixing — ess_checks","text":"BEAST2 run TransPhylo run, pull effective sample size estimated parameters. Check threshold.","code":""},{"path":"/reference/ess_checks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use Effective Sample Size to Check Mixing — ess_checks","text":"","code":"ess_checks(   program = c(\"BEAST2\", \"TransPhylo\"),   path_to_mcmc_log,   burn_in_fraction = 0.1,   sample_interval = 5000,   min_ess )"},{"path":"/reference/ess_checks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use Effective Sample Size to Check Mixing — ess_checks","text":"program Character string. Either \"BEAST2\" \"TransPhylo\". path_to_mcmc_log Character string. Path MCMC log file. burn_in_fraction Numeric. Fraction MCMC chain discard burn-. sample_interval Numeric. Interval samples taken. min_ess Numeric. Minimum effective sample size consider acceptable.","code":""},{"path":"/reference/get_mcctree.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","title":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","text":"Run TreeAnnotator get maximum clade credibility tree BEAST2 tree file.","code":""},{"path":"/reference/get_mcctree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","text":"","code":"get_mcctree(   input_treesfile,   output_dir,   beast_iterations = 1e+07,   burnin_fraction = 1/2,   heights = \"CA\",   treeannotator_path = \"/Applications/\\\"BEAST 2.7.7\\\"/bin/treeannotator\" )"},{"path":"/reference/get_mcctree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","text":"input_treesfile Character string. Path BEAST2 .trees file. output_dir Character string. Path desired output directory MCC tree nexus file. beast_iterations Numeric. Number iterations BEAST2 run. burnin_fraction Numeric. Fraction MCMC chain discard burn-. heights Character string. Node heights tree. Beware using anything common ancestor, get weird trees work TransPhylo. treeannotator_path Character string. Path TreeAnnotator executable.","code":""},{"path":"/reference/regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Linear or Logistic Regression with TransPhylo Results — regression","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"function takes probability estimates TransPhylo runs linear regression , logistic regression probability cutoff label individual infection source specified.","code":""},{"path":"/reference/regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"","code":"regression(   method = c(\"logistic\", \"linear\"),   cleaned_data,   prob_source,   prob_cutoff = NULL )"},{"path":"/reference/regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"method character string specifying type regression run. Can \"linear\" \"logistic\". cleaned_data data frame containing covariates use regression. Must contain column \"SampleID\" sample IDs. prob_source data frame probabilities output TransPhylo columns SampleID prob_source (output run_TransPhylo), indicating probability sample infection source. prob_cutoff numeric specifying probability cutoff use logistic regression. NULL, logistic regression run.","code":""},{"path":"/reference/regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"lm glm object.","code":""},{"path":"/reference/run_TransPhylo.html","id":null,"dir":"Reference","previous_headings":"","what":"Run TransPhylo on a Set of Trees — run_TransPhylo","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"wrapper TransPhylo::infer_multittree_share_param. Can use run TransPhylo set trees, either MCC trees parameter sharing, sample posterior BEAST2 trees without parameter sharing (.e., sample BEAST2 posterior trees single cluster, incorporate phylogenetic uncertainty).","code":""},{"path":"/reference/run_TransPhylo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"","code":"run_TransPhylo(   trees,   cluster_name = NULL,   type = c(\"mcctrees\", \"trees_sample\"),   cluster_dict,   out_dir = \"TransPhylo\",   output_name = \"tp_res\",   ... )"},{"path":"/reference/run_TransPhylo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"trees ape multiPhylo object containing trees analyzed. type \"mcctrees\", MCC trees clusters, names trees need match names trees cluster dictionary. type \"trees_sample\", sample posterior BEAST2 trees single cluster, cluster name provided argument. cluster_name type \"trees_sample\", name cluster trees analyzed. match cluster name cluster dictionary. type \"mcctrees\", argument ignored. type character string specifying type trees analyzed. Can \"mcctrees\" \"trees_sample\". \"mcctrees\", function run TransPhylo MCC trees clusters. \"trees_sample\", function run TransPhylo sample posterior BEAST2 trees single cluster. cluster_dict data frame containing sample_id, cluster_name, collectdt sequence, output assign_snp_clusters. out_dir character string specifying directory TransPhylo results saved. output_name character string specifying name output file. ... Additional arguments passed TransPhylo::infer_multittree_share_param.","code":""},{"path":"/reference/run_TransPhylo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"data frame containing probability sample infection source.","code":""},{"path":"/reference/run_beast2.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Command-Line BEAST2 — run_beast2","title":"Run Command-Line BEAST2 — run_beast2","text":"Run BEAST2 XML file. Tree files, log files, etc. written directory XML file.","code":""},{"path":"/reference/run_beast2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Command-Line BEAST2 — run_beast2","text":"","code":"run_beast2(   input_xml_path,   beast2_path = \"/Applications/\\\"BEAST 2.7.7\\\"/bin/beast\" )"},{"path":"/reference/run_beast2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Command-Line BEAST2 — run_beast2","text":"input_xml_path Character string. Path BEAST2 XML file. beast2_path Character string. Path BEAST2 executable.","code":""},{"path":"/reference/sample_BEAST2_trees.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample BEAST2 Trees — sample_BEAST2_trees","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"function takes BEAST2 posterior trees samples subset , making sure keep tree names.","code":""},{"path":"/reference/sample_BEAST2_trees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"","code":"sample_BEAST2_trees(trees_file, n_trees, seed = NULL, out_dir = NULL)"},{"path":"/reference/sample_BEAST2_trees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"trees_file string path BEAST2 posterior trees file. n_trees integer number trees sample. seed Optionally, seed use tree sampling. out_dir Optionally, string directory write sampled trees .","code":""},{"path":"/reference/sample_BEAST2_trees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"ape multiPhylo object containing tree sample.","code":""}]
