[{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 beast2tpPipeline authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"vignette walk process using beast2tpPipeline package create SNP clusters set fasta files, create xml files cluster, run BEAST2, run TransPhylo BEAST2 results, kind regression probabilities assigned TransPhylo. running BEAST2, set posterior trees cluster. package can two things: Create maximum clade credibility (MCC) tree posterior trees, run TransPhylo multitree MCC trees, sharing parameters can simultaneously estimated. MCC tree single tree attempts summarize posterior trees, like mean median posterior samples values real line. method take one tree summarizes posterior trees cluster, run TransPhylo true phylogenetic trees. Subsample number trees BEAST2 posterior tree samples cluster, run TransPhylo sample trees cluster, rather one summary tree. advantage accounting phylogenetic uncertainty BEAST2 trees, rather assuming one tree truth. However, computationally expensive: instead one TransPhylo run clusters, run TransPhylo cluster separately, time decently-sized set trees. run computing cluster. Additionally, via method, parameter sharing possible. vignette, use package (1). vignette (2), see Using BEAST2 - TransPhylo Pipeline Sample BEAST2 Iterations (Posterior Trees). First, load package library.","code":"library(beast2tpPipeline)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"data-for-this-example","dir":"Articles","previous_headings":"","what":"Data for this Example","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"package comes data collected Kopanyo study, tuberculosis (TB) samples collected two regions Botswana, country high prevalence TB human immodeficiency virus (HIV). Read study . data contain 4 fasta files, one lineage TB. fasta file contains aligned TB sequences study participants. also metadata available samples, including things like HIV status, age, gender, sample collection date, handful variables. Suppose interested using TB sequences draw inference whether HIV makes individual likely transmit TB someone else.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"creating-single-nucleotide-polymorphism-snp-clusters","dir":"Articles","previous_headings":"","what":"Creating Single Nucleotide Polymorphism (SNP) Clusters","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"First, read fasta files metadata R. can take peek data: Notice 1426 sequences corresponding metadata. computationally intensive run BEAST2 sequences simultaneously. Instead, create clusters similar sequences run BEAST2 cluster separately. create clusters, use SNP thresholding. SNPs single nucleotide polymorphisms, single base pair differences sequences. can use differences group sequences clusters likely closely related . use transcluster package . transcluster package developed alongside paper Beyond SNP Threshold: Identifying Outbreak Clusters Using Inferred Transmissions. built handle plain SNP thresholding create clusters, also clustering based likely transmissions. use former, simpler commonly used, latter still available function. assign sequences clusters based SNPs, use assign_snp_clusters, wrapper around transcluster functions. Computing distance matrix large clusters can take time, already distance matrix saved, can pass assign_snp_clusters dist_matrix argument. Now : Next, create actual BEAST2 clusters containing genetic data using create_BEAST2_clusters function. take sequences, split separate objects, keep SNPs (sites across sequences matter BEAST2). discard clusters fewer 4 sequences, clusters fewer 8 SNPs. also add constant sites sequences, deal ascertainment bias BEAST2 due fact keeping SNPs. output function list matrices, matrix cluster sequences. use write xml file run BEAST2. using template xml file available package, save sequences fasta files loaded BEAUti, can providing fasta_dir argument function. running chunks, two objects: cluster_assignments, list lineages containing dataframe giving sample IDs, cluster names, collection dates; snp_matrices, list lineages containing list matrices, matrix cluster sequences.","code":"fasta_files <- list.files(system.file(\"kopanyo\", package = \"beast2tpPipeline\"),                           pattern = \".fasta\", full.names = TRUE) tb_sequences <- lapply(fasta_files, ape::read.dna, format = \"fasta\",                        as.character = TRUE)  metadata <- list.files(system.file(\"kopanyo\", package = \"beast2tpPipeline\"),                        pattern = \".csv\", full.names = TRUE) metadata <- read.csv(metadata) head(metadata) ##   SampleID Lineage genderf1 agenew hivfinal_new gMixture  collectdt smokef1 ## 1 BTB-1139       1        1     52            1        0 2014-07-30       1 ## 2 BTB-1146       1        1     43            1        1 2014-08-05       1 ## 3 BTB-1705       1        1     70            2        1 2015-06-10       1 ## 4  BTB-175       1        2     19            1        1 2013-01-16       2 ## 5 BTB-1774       1        1     38            1        1 2015-07-30       2 ## 6 BTB-1894       1        1     15           NA        1 2015-10-16       2 ##   tb_everf3 alcohol_excess Lineage_detailed ## 1         2              2            1.1.2 ## 2         2              1            1.1.2 ## 3         1              2            1.1.2 ## 4         1              2            1.1.2 ## 5         1              2            1.1.2 ## 6         1              2            1.1.2 dim(metadata) ## [1] 1426   11 # Get collection dates by lineage collectdts <- split(metadata, metadata$Lineage) # Create named vectors of dates, as required by the function collectdts <- lapply(collectdts, function(meta) {   dates <- meta$collectdt   names(dates) <- meta$SampleID   dates })  # Apply the function to each lineage of sequences cluster_assignments <- mapply(assign_snp_clusters,                               # `seqs` is a matrix of sequences                               seqs = tb_sequences,                               # `collectdts` is a named list of vectors of collection dates                               # where the elements are collection dates and the names are sample IDs                                 collectdts = collectdts,                               threshold = 5,                               SIMPLIFY = FALSE) ## Creating SNP-based clusters ## Creating SNP-based clusters ## Creating SNP-based clusters ## Creating SNP-based clusters # Rename clusters to include lineage cluster_assignments <- lapply(seq_along(cluster_assignments), function(i) {   cluster_assignments[[i]]$cluster_name <- paste0(\"lineage\", i, \"_\", cluster_assignments[[i]]$cluster_name)   cluster_assignments[[i]] })  # Take a look at the cluster assignments lapply(cluster_assignments, head) ## [[1]] ##   sample_id      cluster_name  collectdt ## 1  BTB-1023 lineage1_cluster1 2014-05-13 ## 2  BTB-1058 lineage1_cluster2 2014-06-04 ## 3  BTB-1088 lineage1_cluster3 2014-06-25 ## 4    BTB-10 lineage1_cluster4 2012-09-10 ## 5  BTB-1133 lineage1_cluster5 2014-07-25 ## 6  BTB-1139 lineage1_cluster6 2014-07-30 ##  ## [[2]] ##   sample_id      cluster_name  collectdt ## 1  BTB-1000 lineage2_cluster1 2014-04-28 ## 2  BTB-1014 lineage2_cluster2 2014-05-07 ## 3  BTB-1025 lineage2_cluster3 2014-05-13 ## 4  BTB-1115 lineage2_cluster4 2014-07-16 ## 5  BTB-1123 lineage2_cluster5 2014-07-16 ## 6  BTB-1160 lineage2_cluster6 2014-08-12 ##  ## [[3]] ##   sample_id      cluster_name  collectdt ## 1   BTB-119 lineage3_cluster1 2012-12-03 ## 2  BTB-1259 lineage3_cluster2 2014-09-25 ## 3  BTB-1344 lineage3_cluster3 2014-11-11 ## 4  BTB-1410 lineage3_cluster1 2014-12-10 ## 5   BTB-155 lineage3_cluster1 2013-01-07 ## 6  BTB-1698 lineage3_cluster1 2015-06-08 ##  ## [[4]] ##   sample_id      cluster_name  collectdt ## 1  BTB-1001 lineage4_cluster1 2014-04-28 ## 2  BTB-1003 lineage4_cluster2 2014-04-25 ## 3  BTB-1005 lineage4_cluster3 2014-04-30 ## 4  BTB-1007 lineage4_cluster4 2014-05-02 ## 5  BTB-1009 lineage4_cluster5 2014-05-05 ## 6  BTB-1010 lineage4_cluster6 2014-05-05 # For each lineage, use the cluster assignments to put the sequences # into clusters snp_matrices <- lapply(seq_along(tb_sequences), function(lineage_index) {   # Pull the sequences and cluster assignments for this lineage   tb_seq_lineage <- tb_sequences[[lineage_index]]   cluster_assignments_lineage <- cluster_assignments[[lineage_index]]   create_BEAST2_clusters(seqs = tb_seq_lineage,                          cluster_assignments = cluster_assignments_lineage,                          min_cluster_size = 4,                          min_varsites = 8,                          snps_only = TRUE,                          constant_sites = \"acgt\") })  # Take a look at the clusters from the first lineage snp_matrices[[1]] ## $lineage1_cluster6 ##          [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## BTB-1139 \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"c\"  \"t\"  \"c\"   \"c\"   \"t\"   \"c\"   ## BTB-1146 \"a\"  \"c\"  \"g\"  \"t\"  \"a\"  \"t\"  \"g\"  \"c\"  \"t\"  \"t\"   \"t\"   \"t\"   \"c\"   ## BTB-1705 \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"t\"  \"t\"  \"c\"   \"c\"   \"t\"   \"c\"   ## BTB-175  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"c\"  \"t\"  \"c\"   \"c\"   \"c\"   \"t\"   ## BTB-1774 \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"c\"  \"c\"  \"t\"  \"c\"   \"c\"   \"c\"   \"t\"   ## BTB-262  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"c\"  \"t\"  \"c\"   \"c\"   \"t\"   \"c\"   ## BTB-604  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"c\"  \"c\"  \"c\"   \"c\"   \"t\"   \"c\"   ##          [,14] [,15] [,16] [,17] [,18] ## BTB-1139 \"g\"   \"g\"   \"c\"   \"c\"   \"g\"   ## BTB-1146 \"g\"   \"g\"   \"c\"   \"c\"   \"a\"   ## BTB-1705 \"g\"   \"g\"   \"c\"   \"t\"   \"g\"   ## BTB-175  \"a\"   \"t\"   \"t\"   \"c\"   \"g\"   ## BTB-1774 \"a\"   \"t\"   \"t\"   \"c\"   \"g\"   ## BTB-262  \"g\"   \"g\"   \"c\"   \"c\"   \"g\"   ## BTB-604  \"g\"   \"g\"   \"c\"   \"c\"   \"g\"   ##  ## $lineage1_cluster7 ##          [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## BTB-1332 \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"c\"  \"g\"  \"a\"  \"t\"   \"t\"   \"c\"   \"a\"   ## BTB-1645 \"a\"  \"c\"  \"g\"  \"t\"  \"t\"  \"a\"  \"c\"  \"t\"  \"a\"  \"t\"   \"t\"   \"c\"   \"g\"   ## BTB-584  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"c\"  \"g\"  \"a\"  \"t\"   \"t\"   \"g\"   \"a\"   ## BTB-640  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"c\"  \"g\"  \"g\"  \"c\"   \"t\"   \"c\"   \"g\"   ## BTB-665  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"g\"  \"a\"  \"t\"   \"a\"   \"c\"   \"a\"   ##          [,14] ## BTB-1332 \"g\"   ## BTB-1645 \"g\"   ## BTB-584  \"g\"   ## BTB-640  \"a\"   ## BTB-665  \"g\""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"creating-xml-files-for-beast2","dir":"Articles","previous_headings":"","what":"Creating XML Files for BEAST2","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"cluster, create xml file BEAST2. general, BEAUti used create xml files BEAST2, using model mostly across clusters. TB data, package comes template xml function create_cluster_xml fill necessary information cluster. model associated xml template: Strict clock model HKY substitution model Coalescent constant population tree prior Uniform clock rate prior, user-supplied bounds Log-normal(1, 1.25) (w/ upper bound 1) frequency parameter Log-normal(1, 1.25) transition-transversion parameter HKY (kappa) Log-normal(1, 1.25) coalescent population size parameter function create xml files requires sequences (SNPs, us) cluster, name cluster, sampling dates sequences cluster, directory output xml files . function return anything, writes xml files directory specified out_dir. Messages printed xml file written.","code":"# For each lineage, write the xml files for all clusters invisible(lapply(seq_along(snp_matrices), function(lineage_index) {   # Get list of clusters for the lineage   lineage_seqs <- snp_matrices[[lineage_index]]   # Get cluster assignments data frame for the lineage   cluster_assignments_lineage <- cluster_assignments[[lineage_index]]   create_xml_files(seqs_list = lineage_seqs,                    cluster_assignments = cluster_assignments_lineage,                    out_dir = system.file(\"mcc_trees_example\", \"BEAST2\",                                          package = \"beast2tpPipeline\")) }))"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"running-beast2","dir":"Articles","previous_headings":"","what":"Running BEAST2","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"Next, run BEAST2 xml files just created. use run_beast2 function, calls command-line BEAST2 using system. may need change beast2_path argument depending version BEAST2 installed installed . parallelized code using parallel package. necessary, can speed process multiple cores available. Note work Windows, ways parallelize Windows machines. running BEAST2, cluster, log file tree file. log file logs MCMC sampling process, tree file contains posterior trees. First, quick check mixing MCMC, can make sure effective sample size (ESS) 200 parameters. can using ess_checks function, calls package tracerer. ESS low, may want consider re-running BEAST2 iterations. sure also look traceplots MCMC run, easiest Tracer.","code":"cores <- parallel::detectCores() / 2 input_xml <- list.files(system.file(\"mcc_trees_example\", \"BEAST2\",                                     package = \"beast2tpPipeline\"),                         pattern = \"\\\\.xml\", full.names = TRUE) invisible(parallel::mclapply(input_xml, run_beast2, mc.cores = cores)) beast_logs <- list.files(system.file(\"mcc_trees_example\", \"BEAST2\",                                      package = \"beast2tpPipeline\"),                          pattern = \"\\\\.log\", full.names = TRUE) invisible(sapply(beast_logs, function(log) {   ess_checks(\"BEAST2\", log, min_ess = 200) })) ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## lineage4_cluster183.log: ## ESS is too low for 2 parameters ##  ESS: 117    ESS: 162 ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"creating-maximum-clade-credibility-trees","dir":"Articles","previous_headings":"","what":"Creating Maximum Clade Credibility Trees","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"Next, create maximum clade credibility (MCC) tree posterior trees. MCC tree single tree attempts summarize posterior trees, like mean median posterior samples values real line. use get_mcctree function . get_mcctree calls command-line TreeAnnotator BEAST2 suite, may need change treeannotator_path argument depending TreeAnnotator installed. function outputs nothing, MCC trees saved specified output directory. MCC trees look like , example:  associated error bars node uncertainty tree topology, accounted TransPhylo.","code":"trees_files <- list.files(system.file(\"mcc_trees_example\", \"BEAST2\",                                       package = \"beast2tpPipeline\"),                           pattern = \".trees\", full.names = TRUE) out_dir <- system.file(\"mcc_trees_example\", \"BEAST2\", \"mcctree\",                        package = \"beast2tpPipeline\") invisible(parallel::mclapply(seq_along(trees_files), function(i) {   get_mcctree(input_treesfile = trees_files[i], output_dir = out_dir) }, mc.cores = cores))"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"running-transphylo-on-the-mcc-trees","dir":"Articles","previous_headings":"","what":"Running TransPhylo on the MCC Trees","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"Now MCC trees, can run TransPhylo . TransPhylo package tries infer “infected ” tree, transmission tree, taking phylogenetic tree data. reality, uncertainty phylogenetic tree, TransPhylo account . use run_TransPhylo function run TransPhylo MCC trees. first read MCC trees created , make sure names match names cluster assignments data frame (BEAST2 slight renaming outputs automatically), run TransPhylo. can run TransPhylo trees , sharing couple parameters common across trees can estimated simultaneously. function outputs data frame containing sample ID probability sample infection source, .e., probability infected someone else TB. also saves TransPhylo results (resTransPhylo object output TransPhylo::infer_multittree_share_param) .rds file specified output directory. can also use ess_checks function check mixing TransPhylo run, probably useful look traceplots estimated parameters. example , using TransPhylo function first cluster.  TransPhylo also provides methods summarizing posterior trees, plotting result. example, can get “medoid” (extension median) tree plot . , phylogenetic tree plotted colors, color represents individual asterisks represent transmission events. TransPhylo object called ctree, combined phylogenetic/transmission tree (“colored tree”).  also “consensus” tree, built combining clades occurring least fraction posterior samples. tree necessarily tree posterior samples. can plotted plot. TransPhylo object called ttree, transmission tree.  may also interested looking distribution probabilities assigned TransPhylo:","code":"# Read the trees and manipulate the names to make sure they match # the names in cluster_assignments mcc_trees_files <- list.files(system.file(\"mcc_trees_example\",                                           \"BEAST2\", \"mcctree\",                                           package = \"beast2tpPipeline\"),                               pattern = \".tree\", full.names = TRUE) mcc_trees <- lapply(mcc_trees_files, ape::read.nexus) names(mcc_trees) <- gsub(\".nexus\", \"\", basename(mcc_trees_files)) names(mcc_trees) <- gsub(\".*-\", \"\", names(mcc_trees)) # Want to run trees from all lineages together, so paste the cluster # assignments list of dataframes into one dataframe all_cluster_assignments <- do.call(rbind, cluster_assignments) # Run TransPhylo on the MCC trees prob_source <- run_TransPhylo(mcc_trees,                               type = \"mcctrees\",                               cluster_dict = all_cluster_assignments,                               out_dir = system.file(\"mcc_trees_example\",                                                     \"TransPhylo\",                                                     package = \"beast2tpPipeline\"),                               w.shape = 10,                               w.scale = 0.1,                               prior_pi_a = 1,                               prior_pi_b = 19,                               share = c(\"neg\", \"off.r\"),                               startNeg = 1.48,                               mcmcIterations = 100000) transphylo_res <- readRDS(transphylo_res_file) TransPhylo::plotTraces(transphylo_res[[1]]) medoid <- TransPhylo::medTTree(transphylo_res[[1]]) TransPhylo::plotCTree(medoid) cons <- TransPhylo::consTTree(transphylo_res[[1]]) plot(cons) hist(prob_source$prob, main = \"Distribution of TransPhylo Probabilities\",      xlab = \"Probability of being an infector\", col = \"lightblue\")"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"regression-with-transphylo-results","dir":"Articles","previous_headings":"","what":"Regression with TransPhylo Results","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"Finally, can kind regression probabilities assigned TransPhylo. run linear regression probabilities response variable HIV status predictor. use regression function . can add covariates adding columns cleaned_data data frame. regression function automatically remove rows missing values. Alternatively, probability threshold can set mark individuals infectors non-infectors, logistic regression may run. done setting method argument regression \"logistic\" specifying threshold. Since misclassification infector/non-infector status, can also run logistic regression misclassification using simple Bayesian method. done setting method argument regression “bayesian_logistic_misclass”.","code":"# Get dataframe with covariates for regression cleaned_data <- metadata[, c(\"SampleID\", \"hivfinal_new\")] cleaned_data <- cleaned_data[complete.cases(cleaned_data), ] cleaned_data$hivfinal_new <- cleaned_data$hivfinal_new - 1 # Run a linear model with the probabilities from TransPhylo mdl <- regression(method = \"linear\",                   cleaned_data = cleaned_data,                   prob_source = prob_source) summary(mdl) # Get dataframe with covariates for regression, add age and gender cleaned_data <- metadata[, c(\"SampleID\", \"hivfinal_new\", \"genderf1\",                              \"tb_everf3\", \"smokef1\", \"alcohol_excess\")] cleaned_data <- cleaned_data[complete.cases(cleaned_data), ] cleaned_data[, 2:6] <- apply(cleaned_data[, 2:6], 2,                              function(x) as.numeric(x) - 1) # Run a linear model with the probabilities from TransPhylo mdl <- regression(method = \"linear\",                   cleaned_data = cleaned_data,                   prob_source = prob_source) summary(mdl) ##  ## Call: ## lm(formula = prob_source ~ ., data = cleaned_data) ##  ## Residuals: ##      Min       1Q   Median       3Q      Max  ## -0.22528 -0.17311 -0.15239  0.01174  0.83791  ##  ## Coefficients: ##                 Estimate Std. Error t value Pr(>|t|)   ## (Intercept)     0.126011   0.057209   2.203   0.0286 * ## hivfinal_new    0.039487   0.040426   0.977   0.3297   ## genderf1       -0.011014   0.043591  -0.253   0.8007   ## tb_everf3       0.007609   0.049439   0.154   0.8778   ## smokef1         0.052170   0.051089   1.021   0.3082   ## alcohol_excess -0.020719   0.049316  -0.420   0.6748   ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 0.3077 on 234 degrees of freedom ## Multiple R-squared:  0.008643,   Adjusted R-squared:  -0.01254  ## F-statistic: 0.408 on 5 and 234 DF,  p-value: 0.843 # Run a logistic model with the probabilities from TransPhylo # Set the probability threshold to 0.6, where prob >= 0.6 is # considered an infector mdl_logistic <- regression(method = \"logistic\",                            cleaned_data = cleaned_data,                            prob_source = prob_source,                            prob_cutoff = 0.6) summary(mdl_logistic) ##  ## Call: ## glm(formula = tp_source ~ ., family = \"binomial\", data = cleaned_data) ##  ## Coefficients: ##                Estimate Std. Error z value Pr(>|z|)     ## (Intercept)    -2.57277    0.61177  -4.205 2.61e-05 *** ## hivfinal_new    0.61646    0.40656   1.516    0.129     ## genderf1       -0.03172    0.42411  -0.075    0.940     ## tb_everf3      -0.10814    0.50432  -0.214    0.830     ## smokef1         1.03882    0.55876   1.859    0.063 .   ## alcohol_excess -0.52863    0.47714  -1.108    0.268     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for binomial family taken to be 1) ##  ##     Null deviance: 184.70  on 239  degrees of freedom ## Residual deviance: 178.82  on 234  degrees of freedom ## AIC: 190.82 ##  ## Number of Fisher Scoring iterations: 5 # Get odds ratios (adjusted for other covariates) adj_odds_ratios <- data.frame(est = exp(mdl_logistic$coefficients),                               row.names = names(mdl_logistic$coefficients)) adj_odds_ratios <- cbind(adj_odds_ratios, exp(confint(mdl_logistic))) ## Waiting for profiling to be done... adj_odds_ratios ##                       est      2.5 %    97.5 % ## (Intercept)    0.07632382 0.02069694 0.2330317 ## hivfinal_new   1.85236668 0.84517253 4.2139991 ## genderf1       0.96877762 0.41671834 2.2236658 ## tb_everf3      0.89750391 0.34946563 2.6086441 ## smokef1        2.82587567 0.99353282 9.1007819 ## alcohol_excess 0.58941296 0.23284878 1.5307532 # Require that all covariates have columns of type numeric numeric_data <- cleaned_data numeric_data$agenew <- as.numeric(numeric_data$agenew) numeric_data$genderf1 <- as.numeric(numeric_data$genderf1) - 1 numeric_data$hivfinal_new <- as.numeric(numeric_data$hivfinal_new) - 1 samples_logistic <- regression(method = \"bayesian_logistic_misclass\",                                cleaned_data = numeric_data,                                prob_source = prob_source,                                prob_cutoff = 0.6,                                sensitivity = 0.28,                                specificity = 0.97) # Pull the samples for the hiv coefficient, which are the log adjusted # odds ratios for the logistic regression summary(exp(samples_logistic$beta[1, ]))"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/mcc_tree_pipeline.html","id":"exploration-of-the-pipeline","dir":"Articles","previous_headings":"","what":"Exploration of the Pipeline","title":"Using the BEAST2 - TransPhylo Pipeline with Maximum Clade Credibility Trees","text":"package makes convenient change parts pipeline explore impact changes results. example, suppose want change sampling fraction prior TransPhylo, get new results, linear regression results, compare old results.  Now updated probabilities, can compare distribution distribution old sampling fraction prior.  can look individual changes probabilities via scatterplot, point represents sample, x-axis gives probability old sampling fraction prior, y-axis gives probability new sampling fraction prior.  can also redo logistic () regression new probabilities, look new odds ratios. can compare odds ratio HIV status two models:","code":"# Run TransPhylo on the MCC trees with a new sampling fraction prior # Using same MCC trees we have already read in prob_source_new_pi <- run_TransPhylo(mcc_trees,                                      type = \"mcctrees\",                                      cluster_dict = all_cluster_assignments,                                      out_dir = system.file(\"mcc_trees_example\",                                                            \"TransPhylo\",                                                            package = \"beast2tpPipeline\"),                                      output_name = \"tp_res_changed_sampling_frac\",                                      w.shape = 10,                                      w.scale = 0.1,                                      prior_pi_a = 26,                                      prior_pi_b = 74,                                      share = c(\"neg\", \"off.r\"),                                      startNeg = 1.48,                                      mcmcIterations = 100000)  # Look at some traceplots again transphylo_res <- readRDS(transphylo_res_file) TransPhylo::plotTraces(transphylo_res[[1]]) hist(prob_source$prob, main = \"Distribution of TransPhylo Probabilities\",      xlab = \"Probability of being an infector\", col = \"lightblue\") colnames(prob_source_new_pi) <- c(\"SampleID\", \"prob_source_new_pi\") prob_source_pairs <- merge(prob_source, prob_source_new_pi, by = \"SampleID\") plot(prob_source_pairs$prob_source, prob_source_pairs$prob_source_new_pi,      xlab = \"Prob Source Under Beta(1,19) Sampling Fraction Prior\", ylab = \"Prob Source Under Beta(26,74) Sampling Fraction Prior\",      main = \"Comparison of TransPhylo Probabilities of Being an Infection Source\") abline(a = 0, b = 1, col = \"darkgreen\") spline_fit <- smooth.spline(prob_source_pairs$prob_source,                             prob_source_pairs$prob_source_new_pi,                             df = 5) lines(spline_fit, col = \"darkgreen\", lty = 2) colnames(prob_source_new_pi) <- c(\"SampleID\", \"prob_source\") mdl_logistic_new <- regression(method = \"logistic\",                                cleaned_data = cleaned_data,                                prob_source = prob_source_new_pi,                                prob_cutoff = 0.6) summary(mdl_logistic_new) ##  ## Call: ## glm(formula = tp_source ~ ., family = \"binomial\", data = cleaned_data) ##  ## Coefficients: ##                Estimate Std. Error z value Pr(>|z|)     ## (Intercept)     -2.1106     0.5318  -3.969 7.22e-05 *** ## hivfinal_new     0.3901     0.3611   1.080    0.280     ## genderf1         0.1623     0.3811   0.426    0.670     ## tb_everf3       -0.0882     0.4450  -0.198    0.843     ## smokef1          0.4950     0.4820   1.027    0.304     ## alcohol_excess  -0.1397     0.4434  -0.315    0.753     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for binomial family taken to be 1) ##  ##     Null deviance: 213.02  on 239  degrees of freedom ## Residual deviance: 210.53  on 234  degrees of freedom ## AIC: 222.53 ##  ## Number of Fisher Scoring iterations: 4 # Get odds ratios (adjusted for other covariates) adj_odds_ratios_new <- data.frame(est = exp(mdl_logistic_new$coefficients),                                   row.names = names(mdl_logistic_new$coefficients)) adj_odds_ratios_new <- cbind(adj_odds_ratios_new, exp(confint(mdl_logistic_new))) ## Waiting for profiling to be done... adj_odds_ratios_new ##                      est      2.5 %    97.5 % ## (Intercept)    0.1211602 0.03975307 0.3245642 ## hivfinal_new   1.4771205 0.73109189 3.0362124 ## genderf1       1.1761967 0.55457392 2.4899201 ## tb_everf3      0.9155799 0.39564919 2.3125728 ## smokef1        1.6405469 0.65534985 4.4001744 ## alcohol_excess 0.8696210 0.36854637 2.1198239"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/tree_sample_pipeline.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using the BEAST2 - TransPhylo Pipeline with a Sample of BEAST2 Iterations (Posterior Trees)","text":"vignette walk process using beast2tpPipeline package create SNP clusters set fasta files, create xml files cluster, run BEAST2, run TransPhylo BEAST2 results, kind regression probabilities assigned TransPhylo. running BEAST2, set posterior trees cluster. package can two things: Create maximum clade credibility (MCC) tree posterior trees, run TransPhylo multitree MCC trees, sharing parameters can simultaneously estimated. MCC tree single tree attempts summarize posterior trees, like mean median posterior samples values real line. method take one tree summarizes posterior trees cluster, run TransPhylo true phylogenetic trees. Subsample number trees BEAST2 posterior tree samples cluster, run TransPhylo sample trees cluster, rather one summary tree. advantage accounting phylogenetic uncertainty BEAST2 trees, rather assuming one tree truth. However, computationally expensive: instead one TransPhylo run clusters, run TransPhylo cluster separately, time decently-sized set trees. run computing cluster. Additionally, via method, parameter sharing possible. vignette, use package (2). vignette (1), see Using BEAST2 - TransPhylo Pipeline Maximum Clade Credibility Trees. First, load package library.","code":"library(beast2tpPipeline)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/tree_sample_pipeline.html","id":"data-for-this-example","dir":"Articles","previous_headings":"","what":"Data for this Example","title":"Using the BEAST2 - TransPhylo Pipeline with a Sample of BEAST2 Iterations (Posterior Trees)","text":"package comes data collected Kopanyo study, tuberculosis (TB) samples collected two regions Botswana, country high prevalence TB human immodeficiency virus (HIV). Read study . data contain 4 fasta files, one lineage TB. fasta file contains aligned TB sequences study participants. also metadata available samples, including things like HIV status, age, gender, sample collection date, handful variables. Suppose interested using TB sequences draw inference whether HIV makes individual likely transmit TB someone else.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/tree_sample_pipeline.html","id":"creating-single-nucleotide-polymorphism-snp-clusters","dir":"Articles","previous_headings":"","what":"Creating Single Nucleotide Polymorphism (SNP) Clusters","title":"Using the BEAST2 - TransPhylo Pipeline with a Sample of BEAST2 Iterations (Posterior Trees)","text":"First, read fasta files metadata R. can take peek data: Notice 1426 sequences corresponding metadata. computationally intensive run BEAST2 sequences simultaneously. Instead, create clusters similar sequences run BEAST2 cluster separately. create clusters, use SNP thresholding. SNPs single nucleotide polymorphisms, single base pair differences sequences. can use differences group sequences clusters likely closely related . use transcluster package . transcluster package developed alongside paper Beyond SNP Threshold: Identifying Outbreak Clusters Using Inferred Transmissions. built handle plain SNP thresholding create clusters, also clustering based likely transmissions. use former, simpler commonly used, latter still available function. assign sequences clusters based SNPs, use assign_snp_clusters, wrapper around transcluster functions. Computing distance matrix large clusters can take time, already distance matrix saved, can pass assign_snp_clusters dist_matrix argument. Now : Next, create actual BEAST2 clusters using create_BEAST2_clusters function. take sequences, split separate objects, keep SNPs (sites across sequences matter BEAST2). discard clusters fewer 4 sequences, clusters fewer 8 SNPs. also add constant sites sequences, deal ascertainment bias BEAST2 due fact keeping SNPs. output function list matrices, matrix cluster sequences. use write xml file run BEAST2. using template xml file available package, save sequences fasta files loaded BEAUti, can providing fasta_dir argument function. running chunks, two objects: cluster_assignments, list lineages containing dataframe giving sample IDs, cluster names, collection dates; snp_matrices, list lineages containing list matrices, matrix cluster sequences.","code":"fasta_files <- list.files(system.file(\"kopanyo\", package = \"beast2tpPipeline\"),                           pattern = \".fasta\", full.names = TRUE) tb_sequences <- lapply(fasta_files, ape::read.dna, format = \"fasta\",                        as.character = TRUE)  metadata <- list.files(system.file(\"kopanyo\", package = \"beast2tpPipeline\"),                        pattern = \".csv\", full.names = TRUE) metadata <- read.csv(metadata) head(metadata) ##   SampleID Lineage genderf1 agenew hivfinal_new gMixture  collectdt smokef1 ## 1 BTB-1139       1        1     52            1        0 2014-07-30       1 ## 2 BTB-1146       1        1     43            1        1 2014-08-05       1 ## 3 BTB-1705       1        1     70            2        1 2015-06-10       1 ## 4  BTB-175       1        2     19            1        1 2013-01-16       2 ## 5 BTB-1774       1        1     38            1        1 2015-07-30       2 ## 6 BTB-1894       1        1     15           NA        1 2015-10-16       2 ##   tb_everf3 alcohol_excess Lineage_detailed ## 1         2              2            1.1.2 ## 2         2              1            1.1.2 ## 3         1              2            1.1.2 ## 4         1              2            1.1.2 ## 5         1              2            1.1.2 ## 6         1              2            1.1.2 dim(metadata) ## [1] 1426   11 # Get collection dates by lineage collectdts <- split(metadata, metadata$Lineage) # Create named vectors of dates, as required by the function collectdts <- lapply(collectdts, function(meta) {   dates <- meta$collectdt   names(dates) <- meta$SampleID   dates })  # Apply the function to each lineage of sequences cluster_assignments <- mapply(assign_snp_clusters,                               # `seqs` is a matrix of sequences                               seqs = tb_sequences,                               # `collectdts` is a named list of vectors of collection dates                               # where the elements are collection dates and the names are sample IDs                                 collectdts = collectdts,                               threshold = 5,                               SIMPLIFY = FALSE) ## Creating SNP-based clusters ## Creating SNP-based clusters ## Creating SNP-based clusters ## Creating SNP-based clusters # Rename clusters to include lineage cluster_assignments <- lapply(seq_along(cluster_assignments), function(i) {   cluster_assignments[[i]]$cluster_name <- paste0(\"lineage\", i, \"_\", cluster_assignments[[i]]$cluster_name)   cluster_assignments[[i]] })  # Take a look at the cluster assignments lapply(cluster_assignments, head) ## [[1]] ##   sample_id      cluster_name  collectdt ## 1  BTB-1023 lineage1_cluster1 2014-05-13 ## 2  BTB-1058 lineage1_cluster2 2014-06-04 ## 3  BTB-1088 lineage1_cluster3 2014-06-25 ## 4    BTB-10 lineage1_cluster4 2012-09-10 ## 5  BTB-1133 lineage1_cluster5 2014-07-25 ## 6  BTB-1139 lineage1_cluster6 2014-07-30 ##  ## [[2]] ##   sample_id      cluster_name  collectdt ## 1  BTB-1000 lineage2_cluster1 2014-04-28 ## 2  BTB-1014 lineage2_cluster2 2014-05-07 ## 3  BTB-1025 lineage2_cluster3 2014-05-13 ## 4  BTB-1115 lineage2_cluster4 2014-07-16 ## 5  BTB-1123 lineage2_cluster5 2014-07-16 ## 6  BTB-1160 lineage2_cluster6 2014-08-12 ##  ## [[3]] ##   sample_id      cluster_name  collectdt ## 1   BTB-119 lineage3_cluster1 2012-12-03 ## 2  BTB-1259 lineage3_cluster2 2014-09-25 ## 3  BTB-1344 lineage3_cluster3 2014-11-11 ## 4  BTB-1410 lineage3_cluster1 2014-12-10 ## 5   BTB-155 lineage3_cluster1 2013-01-07 ## 6  BTB-1698 lineage3_cluster1 2015-06-08 ##  ## [[4]] ##   sample_id      cluster_name  collectdt ## 1  BTB-1001 lineage4_cluster1 2014-04-28 ## 2  BTB-1003 lineage4_cluster2 2014-04-25 ## 3  BTB-1005 lineage4_cluster3 2014-04-30 ## 4  BTB-1007 lineage4_cluster4 2014-05-02 ## 5  BTB-1009 lineage4_cluster5 2014-05-05 ## 6  BTB-1010 lineage4_cluster6 2014-05-05 # For each lineage, use the cluster assignments to put the sequences # into clusters snp_matrices <- lapply(seq_along(tb_sequences), function(lineage_index) {   # Pull the sequences and cluster assignments for this lineage   tb_seq_lineage <- tb_sequences[[lineage_index]]   cluster_assignments_lineage <- cluster_assignments[[lineage_index]]   create_BEAST2_clusters(seqs = tb_seq_lineage,                          cluster_assignments = cluster_assignments_lineage,                          min_cluster_size = 4,                          min_varsites = 8,                          snps_only = TRUE,                          constant_sites = \"acgt\") })  # Take a look at the clusters from the first lineage snp_matrices[[1]] ## $lineage1_cluster6 ##          [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## BTB-1139 \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"c\"  \"t\"  \"c\"   \"c\"   \"t\"   \"c\"   ## BTB-1146 \"a\"  \"c\"  \"g\"  \"t\"  \"a\"  \"t\"  \"g\"  \"c\"  \"t\"  \"t\"   \"t\"   \"t\"   \"c\"   ## BTB-1705 \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"t\"  \"t\"  \"c\"   \"c\"   \"t\"   \"c\"   ## BTB-175  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"c\"  \"t\"  \"c\"   \"c\"   \"c\"   \"t\"   ## BTB-1774 \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"c\"  \"c\"  \"t\"  \"c\"   \"c\"   \"c\"   \"t\"   ## BTB-262  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"c\"  \"t\"  \"c\"   \"c\"   \"t\"   \"c\"   ## BTB-604  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"c\"  \"c\"  \"c\"   \"c\"   \"t\"   \"c\"   ##          [,14] [,15] [,16] [,17] [,18] ## BTB-1139 \"g\"   \"g\"   \"c\"   \"c\"   \"g\"   ## BTB-1146 \"g\"   \"g\"   \"c\"   \"c\"   \"a\"   ## BTB-1705 \"g\"   \"g\"   \"c\"   \"t\"   \"g\"   ## BTB-175  \"a\"   \"t\"   \"t\"   \"c\"   \"g\"   ## BTB-1774 \"a\"   \"t\"   \"t\"   \"c\"   \"g\"   ## BTB-262  \"g\"   \"g\"   \"c\"   \"c\"   \"g\"   ## BTB-604  \"g\"   \"g\"   \"c\"   \"c\"   \"g\"   ##  ## $lineage1_cluster7 ##          [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## BTB-1332 \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"c\"  \"g\"  \"a\"  \"t\"   \"t\"   \"c\"   \"a\"   ## BTB-1645 \"a\"  \"c\"  \"g\"  \"t\"  \"t\"  \"a\"  \"c\"  \"t\"  \"a\"  \"t\"   \"t\"   \"c\"   \"g\"   ## BTB-584  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"c\"  \"g\"  \"a\"  \"t\"   \"t\"   \"g\"   \"a\"   ## BTB-640  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"c\"  \"g\"  \"g\"  \"c\"   \"t\"   \"c\"   \"g\"   ## BTB-665  \"a\"  \"c\"  \"g\"  \"t\"  \"c\"  \"c\"  \"g\"  \"g\"  \"a\"  \"t\"   \"a\"   \"c\"   \"a\"   ##          [,14] ## BTB-1332 \"g\"   ## BTB-1645 \"g\"   ## BTB-584  \"g\"   ## BTB-640  \"a\"   ## BTB-665  \"g\""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/tree_sample_pipeline.html","id":"creating-xml-files-for-beast2","dir":"Articles","previous_headings":"","what":"Creating XML Files for BEAST2","title":"Using the BEAST2 - TransPhylo Pipeline with a Sample of BEAST2 Iterations (Posterior Trees)","text":"cluster, create xml file BEAST2. general, BEAUti used create xml files BEAST2, using model mostly across clusters. TB data, package comes template xml function create_cluster_xml fill necessary information cluster. model associated xml template: Strict clock model HKY substitution model Coalescent constant population tree prior Uniform clock rate prior, user-supplied bounds Log-normal(1, 1.25) (w/ upper bound 1) frequency parameter Log-normal(1, 1.25) transition-transversion parameter HKY (kappa) Log-normal(1, 1.25) coalescent population size parameter function create xml files requires sequences (SNPs, us) cluster, name cluster, sampling dates sequences cluster, directory output xml files . function return anything, writes xml files directory specified out_dir. Messages printed xml file written.","code":"# For each lineage, write the xml files for all clusters invisible(lapply(seq_along(snp_matrices), function(lineage_index) {   # Get list of clusters for the lineage   lineage_seqs <- snp_matrices[[lineage_index]]   # Get cluster assignments data frame for the lineage   cluster_assignments_lineage <- cluster_assignments[[lineage_index]]   create_xml_files(seqs_list = lineage_seqs,                    cluster_assignments = cluster_assignments_lineage,                    out_dir = system.file(\"mcc_trees_example\", \"BEAST2\",                                          package = \"beast2tpPipeline\")) }))"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/tree_sample_pipeline.html","id":"running-beast2","dir":"Articles","previous_headings":"","what":"Running BEAST2","title":"Using the BEAST2 - TransPhylo Pipeline with a Sample of BEAST2 Iterations (Posterior Trees)","text":"Next, run BEAST2 xml files just created. use run_beast2 function, calls command-line BEAST2 using system. may need change beast2_path argument depending version BEAST2 installed installed . parallelized code using parallel package. necessary, can speed process multiple cores available. Note work Windows, ways parallelize Windows machines. running BEAST2, cluster, log file tree file. log file logs MCMC sampling process, tree file contains posterior trees. First, quick check mixing MCMC, can make sure effective sample size (ESS) 200 parameters. can using ess_checks function, calls package tracerer. ESS low, may want consider re-running BEAST2 iterations. sure also look traceplots MCMC run, easiest Tracer.","code":"cores <- parallel::detectCores() / 2 input_xml <- list.files(system.file(\"mcc_trees_example\", \"BEAST2\",                                     package = \"beast2tpPipeline\"),                         pattern = \"\\\\.xml\", full.names = TRUE) invisible(parallel::mclapply(input_xml, run_beast2, mc.cores = cores)) beast_logs <- list.files(system.file(\"mcc_trees_example\", \"BEAST2\",                                      package = \"beast2tpPipeline\"),                          pattern = \"\\\\.log\", full.names = TRUE) invisible(sapply(beast_logs, function(log) {   ess_checks(\"BEAST2\", log, min_ess = 200) })) ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## lineage4_cluster183.log: ## ESS is too low for 2 parameters ##  ESS: 117    ESS: 162 ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold ## All ESS are above minimum threshold"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/tree_sample_pipeline.html","id":"subsampling-beast2-iterations","dir":"Articles","previous_headings":"","what":"Subsampling BEAST2 Iterations","title":"Using the BEAST2 - TransPhylo Pipeline with a Sample of BEAST2 Iterations (Posterior Trees)","text":"tutorial diverges MCC trees tutorial. , subsample number trees BEAST2 runs, run TransPhylo entire subsample cluster. computationally expensive, best run computing cluster parallel. reason using MCC tree account phylogenetic uncertainty BEAST2 trees. MCC tree functions summary posterior trees, true phylogenetic tree. running TransPhylo subsample trees, can account uncertainty. First, use sample_BEAST2_trees function sample 100 trees BEAST2 run. cluster, gives us:","code":"beast_trees_files <- list.files(system.file(\"mcc_trees_example\", \"BEAST2\",                                             package = \"beast2tpPipeline\"),                                 pattern = \"\\\\.trees\", full.names = TRUE)  beast_trees_list <- lapply(beast_trees_files, function(trees_file) {   sample_BEAST2_trees(trees_file, n_trees = 100, seed = 123) }) library(gridExtra) library(ggtree) ## ggtree v3.14.0 Learn more at https://yulab-smu.top/contribution-tree-data/ ##  ## Please cite: ##  ## Guangchuang Yu, David Smith, Huachen Zhu, Yi Guan, Tommy Tsan-Yuk Lam. ## ggtree: an R package for visualization and annotation of phylogenetic ## trees with their covariates and other associated data. Methods in ## Ecology and Evolution. 2017, 8(1):28-36. doi:10.1111/2041-210X.12628 beast_trees_list[[1]] ## 100 phylogenetic trees # Plot the first cluster's tree sample plots <- list() for (i in 1:100) {   p <- ggtree(beast_trees_list[[1]][i]) + theme_tree2() + theme(plot.margin = margin(0, 0, 0, 0))   plots[[i]] <- p } grid.arrange(grobs = plots, ncol = 10, nrow = 10)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/tree_sample_pipeline.html","id":"running-transphylo-on-the-subsampled-trees","dir":"Articles","previous_headings":"","what":"Running TransPhylo on the Subsampled Trees","title":"Using the BEAST2 - TransPhylo Pipeline with a Sample of BEAST2 Iterations (Posterior Trees)","text":"Now subsample trees cluster, can run TransPhylo cluster. MCC trees tutorial, ran function run_TransPhylo ; , run cluster. code save TransPhylo result posterior probabilities cluster. TransPhylo results large RDS files, included package. infector probabilities saved tree_sample_example directory package. Note: couple clusters run successfully, excluded results. happened explored time permits. can look distribution assigned probabilities, MCC trees tutorial:  directly compare assigned probabilities scatterplot:","code":"# Make sure the tree names match the cluster dictionary names # By naming them after the files they came from, then removing the # file extension & extras that BEAST2 adds to the filenames names(beast_trees_list) <- gsub(\".trees\", \"\", basename(beast_trees_files)) names(beast_trees_list) <- gsub(\".*-\", \"\", names(beast_trees_list))  # Get all cluster assignments in one data frame all_cluster_assignments <- do.call(rbind, cluster_assignments) # Run TransPhylo on the tree samples in parallel # (I'm using the same number of cores as clusters) cores <- min(length(beast_trees_list), parallel::detectCores()) parallel::mclapply(seq_along(beast_trees_list), function(trees_sample_index) {   run_TransPhylo(beast_trees_list[[trees_sample_index]],                  cluster_name = names(beast_trees_list)[trees_sample_index],                  type = \"trees_sample\",                  cluster_dict = all_cluster_assignments,                  out_dir = system.file(\"tree_sample_example\",                                        \"TransPhylo\",                                        package = \"beast2tpPipeline\"),                  output_name = paste0(\"tp_res_\",                                       names(beast_trees_list)[trees_sample_index]),                  w.shape = 10,                  w.scale = 0.1,                  prior_pi_a = 1,                  prior_pi_b = 19,                  startNeg = 1.48,                  mcmcIterations = 100000) }, mc.cores = cores) # Read in prob_source files prob_source_files <- list.files(system.file(\"trees_sample_example\",                                             \"TransPhylo\",                                             package = \"beast2tpPipeline\"),                                 full.names = TRUE) prob_source_list <- lapply(prob_source_files, readRDS) prob_source <- do.call(rbind, prob_source_list) hist(prob_source$prob, main = \"Distribution of TransPhylo Probabilities\",      xlab = \"Probability of being an infector\", col = \"lightblue\") prob_source_mcc <- readRDS(system.file(\"mcc_trees_example\", \"TransPhylo\",                                        \"tp_res_prob_source.rds\",                                        package = \"beast2tpPipeline\")) colnames(prob_source_mcc) <- c(\"SampleID\", \"prob_source_mcc\") prob_source_pairs <- merge(prob_source, prob_source_mcc, by = \"SampleID\") plot(prob_source_pairs$prob_source, prob_source_pairs$prob_source_mcc,      xlab = \"Prob Source Using BEAST2 Tree Sample Method (100 Trees)\", ylab = \"Prob Source Using BEAST2 MCC Trees\",      main = \"Comparison of TransPhylo Probabilities of Being an Infection Source\") abline(a = 0, b = 1, col = \"darkgreen\") spline_fit <- smooth.spline(prob_source_pairs$prob_source,               prob_source_pairs$prob_source_mcc,               spar = 1.75) lines(spline_fit, col = \"darkgreen\", lty = 2)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/articles/tree_sample_pipeline.html","id":"regression-with-transphylo-results","dir":"Articles","previous_headings":"","what":"Regression with TransPhylo Results","title":"Using the BEAST2 - TransPhylo Pipeline with a Sample of BEAST2 Iterations (Posterior Trees)","text":"MCC tree pipeline, can regress probabilities assigned TransPhylo covariates. use Bayesian method handling misclassification. can compare posterior AOR samples obtained using MCC trees method:","code":"# Get dataframe with covariates for regression, add age and gender; # for this method, ensure all are numeric cleaned_data <- metadata[, c(\"SampleID\", \"hivfinal_new\", \"genderf1\",                              \"tb_everf3\", \"smokef1\", \"alcohol_excess\")] cleaned_data <- cleaned_data[complete.cases(cleaned_data), ] cleaned_data[, 2:6] <- apply(cleaned_data[, 2:6], 2,                              function(x) as.numeric(x) - 1) samples_logistic <- regression(method = \"bayesian_logistic_misclass\",                                cleaned_data = cleaned_data,                                prob_source = prob_source,                                prob_cutoff = 0.6,                                sensitivity = 0.28,                                specificity = 0.97) ##  ## SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). ## Chain 1:  ## Chain 1: Gradient evaluation took 8.9e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.89 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1:  ## Chain 1:  ## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) ## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) ## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) ## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) ## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) ## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) ## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) ## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) ## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) ## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) ## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) ## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) ## Chain 1:  ## Chain 1:  Elapsed Time: 0.448 seconds (Warm-up) ## Chain 1:                0.428 seconds (Sampling) ## Chain 1:                0.876 seconds (Total) ## Chain 1:  ##  ## SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). ## Chain 2:  ## Chain 2: Gradient evaluation took 3.6e-05 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2:  ## Chain 2:  ## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) ## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) ## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) ## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) ## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) ## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) ## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) ## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) ## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) ## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) ## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) ## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) ## Chain 2:  ## Chain 2:  Elapsed Time: 0.43 seconds (Warm-up) ## Chain 2:                0.465 seconds (Sampling) ## Chain 2:                0.895 seconds (Total) ## Chain 2:  ##  ## SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). ## Chain 3:  ## Chain 3: Gradient evaluation took 3.6e-05 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3:  ## Chain 3:  ## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) ## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) ## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) ## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) ## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) ## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) ## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) ## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) ## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) ## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) ## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) ## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) ## Chain 3:  ## Chain 3:  Elapsed Time: 0.429 seconds (Warm-up) ## Chain 3:                0.472 seconds (Sampling) ## Chain 3:                0.901 seconds (Total) ## Chain 3:  ##  ## SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). ## Chain 4:  ## Chain 4: Gradient evaluation took 3.6e-05 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4:  ## Chain 4:  ## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) ## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) ## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) ## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) ## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) ## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) ## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) ## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) ## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) ## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) ## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) ## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) ## Chain 4:  ## Chain 4:  Elapsed Time: 0.434 seconds (Warm-up) ## Chain 4:                0.45 seconds (Sampling) ## Chain 4:                0.884 seconds (Total) ## Chain 4: # Pull the samples for the hiv coefficient, which are the log adjusted # odds ratios (AORs) for the logistic regression summary(exp(samples_logistic$beta[1, ])) ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  ##  0.7479  0.9852  1.0217  1.2920  1.3923  2.3130 samples_logistic_mcc <- regression(method = \"bayesian_logistic_misclass\",                                    cleaned_data = cleaned_data,                                    prob_source = prob_source,                                    prob_cutoff = 0.6,                                    sensitivity = 0.28,                                    specificity = 0.97) ##  ## SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). ## Chain 1:  ## Chain 1: Gradient evaluation took 4.3e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.43 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1:  ## Chain 1:  ## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) ## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) ## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) ## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) ## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) ## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) ## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) ## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) ## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) ## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) ## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) ## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) ## Chain 1:  ## Chain 1:  Elapsed Time: 0.423 seconds (Warm-up) ## Chain 1:                0.485 seconds (Sampling) ## Chain 1:                0.908 seconds (Total) ## Chain 1:  ##  ## SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). ## Chain 2:  ## Chain 2: Gradient evaluation took 3.7e-05 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2:  ## Chain 2:  ## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) ## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) ## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) ## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) ## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) ## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) ## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) ## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) ## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) ## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) ## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) ## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) ## Chain 2:  ## Chain 2:  Elapsed Time: 0.421 seconds (Warm-up) ## Chain 2:                0.445 seconds (Sampling) ## Chain 2:                0.866 seconds (Total) ## Chain 2:  ##  ## SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). ## Chain 3:  ## Chain 3: Gradient evaluation took 3.6e-05 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3:  ## Chain 3:  ## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) ## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) ## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) ## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) ## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) ## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) ## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) ## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) ## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) ## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) ## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) ## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) ## Chain 3:  ## Chain 3:  Elapsed Time: 0.423 seconds (Warm-up) ## Chain 3:                0.445 seconds (Sampling) ## Chain 3:                0.868 seconds (Total) ## Chain 3:  ##  ## SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). ## Chain 4:  ## Chain 4: Gradient evaluation took 3.6e-05 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4:  ## Chain 4:  ## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) ## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) ## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) ## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) ## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) ## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) ## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) ## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) ## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) ## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) ## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) ## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) ## Chain 4:  ## Chain 4:  Elapsed Time: 0.413 seconds (Warm-up) ## Chain 4:                0.453 seconds (Sampling) ## Chain 4:                0.866 seconds (Total) ## Chain 4: # Pull the samples for the exponentiated coef and compare boxplot(exp(samples_logistic$beta[1, ]), exp(samples_logistic_mcc$beta[1, ]),         names = c(\"Tree Sample Method\", \"MCC Trees Method\"),         main = \"Comparison of Posterior AOR Samples\",         ylab = \"Adjusted Odds Ratio of Transmission of TB with/without HIV\",         col = c(\"lightblue\", \"lightgreen\"))"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jessalyn Sebastian. Author, maintainer.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Sebastian J (2025). beast2tpPipeline: BEAST2 TransPhylo Regression Pipeline. R package version 0.0.0.9000, https://jessalynnsebastian.github.io/beast2tpPipeline/.","code":"@Manual{,   title = {beast2tpPipeline: BEAST2 to TransPhylo to Regression Pipeline},   author = {Jessalyn Sebastian},   year = {2025},   note = {R package version 0.0.0.9000},   url = {https://jessalynnsebastian.github.io/beast2tpPipeline/}, }"},{"path":[]},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"BEAST2 to TransPhylo to Regression Pipeline","text":"package created work data Kopanyo study, namely fasta files TB sequences associated metadata. defines clear pipeline fasta files sequences associated metadata, creating SNP clusters, running BEAST2, running TransPhylo, regression results. Using genetic data identify transmission risk factors: Statistical assessment application tuberculosis transmission, Goldstein et al. show pipeline biased; BEAST2-TransPhylo pipeline low sensitivity identifying infection sources biases regression coefficients toward zero. package built facilitate exploration qualities pipeline. package built step pipeline associated function. steps functions : Assigning SNP clusters: assign_snp_clusters takes set sequences metadata, assigns sequences SNP clusters. Creating BEAST2 clusters: create_BEAST2_clusters takes SNP clusters separates sequence data cluster, keeping SNPs desired. Creating XML files BEAST2: create_cluster_xml takes SNP data creates XML file BEAST2 run. Running BEAST2: run_beast2 runs BEAST2 XML file. take DNA sequences infer timed phylogenetic tree, tells us ancestry pathogen. Getting MCC trees: get_mcctree takes posterior trees BEAST2 creates maximum clade credibility tree - summary tree, like mean median. (Alternatively, Getting Sample Posterior Trees: sample_BEAST2_trees takes posterior trees BEAST2 subsamples specified number .) Running TransPhylo MCC trees: run_TransPhylo runs TransPhylo MCC trees, sharing parameters can simultaneously estimated. take timed phylogeny use try infer -infected-. (Alternatively, can use run_TransPhylo run TransPhylo subsample BEAST2 trees, without parameter sharing.) Running regression TransPhylo results: regression runs linear logistic regression using TransPhylo results. draw inference relationship covariates individual transmission probabilities.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"BEAST2 to TransPhylo to Regression Pipeline","text":"Install beast2tpPipeline package GitHub: dependencies automatically downloaded. , load package: also need BEAST2 installed computer. can download . use package manager like homebrew, can install BEAST2 brew install beast2 terminal. install suite programs, including BEAST2, BEAUti, TreeAnnotator. probably also want install Tracer look traceplots diagnostics BEAST2 runs. can download Tracer .","code":"devtools::install_github(\"jessalynnsebastian/beast2tpPipeline\", build_vignettes = TRUE) library(beast2tpPipeline)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/assign_snp_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign SNP Clusters to Samples — assign_snp_clusters","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"function assigns SNP clusters samples based SNP distance threshold, , alternatively, based transmission clusters Stimson et al. paper, Beyond SNP Threshold: Identifying Outbreak Clusters Using Inferred Transmissions.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/assign_snp_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"","code":"assign_snp_clusters(   seqs = NULL,   collectdts,   snp_matrix = NULL,   threshold = 5,   clockrate = -1,   transm_rate = -1 )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/assign_snp_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"seqs Matrices containing sequences. collectdts numeric vector collection dates, names corresponding rownames seqs matrix. snp_matrix SNP distances previously computed, include argument avoid re-computing. threshold numeric value SNP threshold, transmission threshold using transmission clusters (see transcluster info). clockrate numeric value clock rate using transmission clusters. transm_rate numeric value transmission rate using transmission clusters.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/assign_snp_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign SNP Clusters to Samples — assign_snp_clusters","text":"data frame containing sample ID, cluster name, collection date sample.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_BEAST2_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"Using SNP cluster information DNA sequences, separate sequences separate DNAbin objcts cluster. desired, keep SNPs.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_BEAST2_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"","code":"create_BEAST2_clusters(   seqs,   cluster_assignments,   min_cluster_size = 4,   min_varsites = 8,   snps_only = TRUE,   constant_sites = \"\",   cluster_dictionary_file = NULL,   fasta_dir = NULL )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_BEAST2_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"seqs matrix DNA sequences, rownames correspond sample IDs, ape::DNAbin object. cluster_assignments data frame cluster assignments, including least sample_id cluster_name, output assign_snp_clusters. Must also include collectdt writing cluster dictionary. min_cluster_size number samples required keep cluster. cluster small, discard . min_varsites number variable sites required keep cluster. enough variable sites, discard cluster. snps_only TRUE, keep SNPs output DNAbin objects. constant_sites string constant sites add beginning sequence. necessary BEAST2 input using SNPs. Defaults empty string. cluster_dictionary_file Optionally, file path write cluster dictionary , containing cluster names, sizes, varsites. fasta_dir Optionally, directory write FASTA files cluster. FASTA files automatically named cluster names.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_BEAST2_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Clusters for BEAST2 Input — create_BEAST2_clusters","text":"named list matrices containing SNPs.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_cluster_xml.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a BEAST2 XML File from a Template — create_cluster_xml","title":"Create a BEAST2 XML File from a Template — create_cluster_xml","text":"Create BEAST2 XML File Template","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_cluster_xml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a BEAST2 XML File from a Template — create_cluster_xml","text":"","code":"create_cluster_xml(   path_to_template,   cluster_seqs,   cluster_name,   cluster_assignments,   mcmc_iterations,   store_every,   min_clockrate,   max_clockrate,   init_clockrate,   whole_genome_length,   out_dir )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_cluster_xml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a BEAST2 XML File from a Template — create_cluster_xml","text":"path_to_template path template XML file. cluster_seqs matrix DNA sequences (SNPs), rownames correspond sample IDs. cluster_name character string specifying name cluster. cluster_assignments data frame cluster assignments, including sample_id, cluster_name, collectdt, output assign_snp_clusters. sample IDs seqs matrices must present data frame. mcmc_iterations number MCMC iterations run. store_every frequency storing trees. min_clockrate minimum clock rate uniform clock rate prior. Defaults tuberculosis genome clock rate. adjust SNPs . max_clockrate maximum clock rate uniform clock rate prior. Defaults tuberculosis genome clock rate. init_clockrate initial clock rate clock rate. whole_genome_length length whole genome. Used adjust clock rate SNPs. Defaults TB length. out_dir directory write output XML file. Files automatically named FASTA names.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_xml_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Create BEAST2 XML Files from a Template — create_xml_files","title":"Create BEAST2 XML Files from a Template — create_xml_files","text":"Use template XML file create new XML files BEAST2 input. function can replace sequences, sampling dates, mcmc iterations, frequency storing trees, , uniform clock rate, minimum maximum clock rates. designed just used provided template file, though theoretically used others. template file written tuberculosis data. contains adjustment ascertainment bias due SNPs, Gamma site model, HKY substitution model, strict clock, Coalescent constant population model, uniform clock rate prior (min/max editable), lognormal(1, 1.25) freqParameter, kappa, popsize priors. template xml contains placeholders: SNP_FILE_NAME_HERE name SNP file ALIGNMENT_INFORMATION_HERE sequence information DATE_INFORMATION_HERE sampling dates CLOCKRATE_MINIMUM_HERE minimum uniform clock rate CLOCKRATE_MAXIMUM_HERE maximum uniform clock rate CLOCKRATE_INITIAL_HERE initial clock rate MCMC_ITERATIONS_HERE number MCMC iterations STORE_EVERY_HERE frequency storing trees","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_xml_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create BEAST2 XML Files from a Template — create_xml_files","text":"","code":"create_xml_files(   path_to_template = system.file(\"xml_template/0_xml_template.xml\", package =     \"beast2tpPipeline\"),   seqs_list,   cluster_assignments,   mcmc_iterations = 2e+07,   store_every = 5000,   min_clockrate = 10^(-8),   max_clockrate = 5 * 10^(-7),   init_clockrate = 10 * min_clockrate,   whole_genome_length = 4.2 * 10^6,   out_dir )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/create_xml_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create BEAST2 XML Files from a Template — create_xml_files","text":"path_to_template path template XML file. seqs_list list matrices DNA sequences (SNPs), rownames correspond sample IDs. cluster_assignments data frame cluster assignments, including sample_id, cluster_name, collectdt, output assign_snp_clusters. sample IDs seqs matrices must present data frame. mcmc_iterations number MCMC iterations run. store_every frequency storing trees. min_clockrate minimum clock rate uniform clock rate prior. Defaults tuberculosis genome clock rate. adjust SNPs . max_clockrate maximum clock rate uniform clock rate prior. Defaults tuberculosis genome clock rate. init_clockrate initial clock rate clock rate. whole_genome_length length whole genome. Used adjust clock rate SNPs. Defaults TB length. out_dir directory write output XML file. Files automatically named FASTA names.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/ess_checks.html","id":null,"dir":"Reference","previous_headings":"","what":"Use Effective Sample Size to Check Mixing — ess_checks","title":"Use Effective Sample Size to Check Mixing — ess_checks","text":"BEAST2 run TransPhylo run, pull effective sample size estimated parameters. Check threshold.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/ess_checks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use Effective Sample Size to Check Mixing — ess_checks","text":"","code":"ess_checks(   program = c(\"BEAST2\", \"TransPhylo\"),   path_to_mcmc_log,   burn_in_fraction = 0.1,   sample_interval = 5000,   min_ess )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/ess_checks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use Effective Sample Size to Check Mixing — ess_checks","text":"program Character string. Either \"BEAST2\" \"TransPhylo\". path_to_mcmc_log Character string. Path MCMC log file. burn_in_fraction Numeric. Fraction MCMC chain discard burn-. sample_interval Numeric. Interval samples taken. min_ess Numeric. Minimum effective sample size consider acceptable.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_mcctree.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","title":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","text":"Run TreeAnnotator get maximum clade credibility tree BEAST2 tree file.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_mcctree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","text":"","code":"get_mcctree(   input_treesfile,   output_dir,   beast_iterations = 2e+07,   burnin_fraction = 1/2,   heights = \"CA\",   treeannotator_path = \"/Applications/\\\"BEAST 2.7.7\\\"/bin/treeannotator\" )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_mcctree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Maximum Clade Credibility Trees Using Command-Line TreeAnnotator — get_mcctree","text":"input_treesfile Character string. Path BEAST2 .trees file. output_dir Character string. Path desired output directory MCC tree nexus file. beast_iterations Numeric. Number iterations BEAST2 run. burnin_fraction Numeric. Fraction MCMC chain discard burn-. heights Character string. Node heights tree. Beware using anything common ancestor, get weird trees work TransPhylo. treeannotator_path Character string. Path TreeAnnotator executable.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_prob_source.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Infector Probabilities from TransPhylo Results — get_prob_source","title":"Get Infector Probabilities from TransPhylo Results — get_prob_source","text":"Get Infector Probabilities TransPhylo Results","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_prob_source.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Infector Probabilities from TransPhylo Results — get_prob_source","text":"","code":"get_prob_source(tp_res, type = c(\"mcctrees\", \"trees_sample\"))"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_prob_source.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Infector Probabilities from TransPhylo Results — get_prob_source","text":"tp_res list resTransPhylo objects. type character string specifying type trees analyzed. Can \"mcctrees\" \"trees_sample\".","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/get_prob_source.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Infector Probabilities from TransPhylo Results — get_prob_source","text":"data frame containing probability sample infection source.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/prep_for_TransPhylo.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare Data for TransPhylo — prep_for_TransPhylo","title":"Prepare Data for TransPhylo — prep_for_TransPhylo","text":"Prepare Data TransPhylo","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/prep_for_TransPhylo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare Data for TransPhylo — prep_for_TransPhylo","text":"","code":"prep_for_TransPhylo(   trees,   cluster_name = NULL,   type = c(\"mcctrees\", \"trees_sample\"),   cluster_dict,   out_dir = \"TransPhylo\",   output_name = \"tp_res\",   ... )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/prep_for_TransPhylo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare Data for TransPhylo — prep_for_TransPhylo","text":"trees ape multiPhylo object containing trees analyzed. type \"mcctrees\", MCC trees clusters, names trees need match names trees cluster dictionary. type \"trees_sample\", sample posterior BEAST2 trees single cluster, cluster name provided argument. cluster_name type \"trees_sample\", name cluster trees analyzed. match cluster name cluster dictionary. type \"mcctrees\", argument ignored. type character string specifying type trees analyzed. Can \"mcctrees\" \"trees_sample\". \"mcctrees\", function run TransPhylo MCC trees clusters. \"trees_sample\", function run TransPhylo sample posterior BEAST2 trees single cluster. cluster_dict data frame containing sample_id, cluster_name, collectdt sequence, output assign_snp_clusters. out_dir character string specifying directory TransPhylo results saved. output_name character string specifying name output file. ... Additional arguments passed TransPhylo::infer_multittree_share_param.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/prep_for_TransPhylo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare Data for TransPhylo — prep_for_TransPhylo","text":"Arguments passed TransPhylo::infer_multittree_share_param().","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Linear or Logistic Regression with TransPhylo Results — regression","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"function takes probability estimates TransPhylo runs linear regression , logistic regression probability cutoff label individual infection source specified.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"","code":"regression(   method = c(\"logistic\", \"linear\", \"bayesian_logistic_misclass\"),   cleaned_data,   prob_source,   prob_cutoff = NULL,   sensitivity = NULL,   specificity = NULL,   ... )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"method character string specifying type regression run. Can \"linear\", \"logistic\", \"bayesian_logistic_misclass\". cleaned_data data frame containing covariates use regression. Must contain column \"SampleID\" sample IDs. prob_source data frame probabilities output TransPhylo columns SampleID prob_source (output run_TransPhylo), indicating probability sample infection source. prob_cutoff numeric specifying probability cutoff use logistic regression. NULL, logistic regression run. sensitivity Numeric. used method \"bayesian_logistic_misclass\". specificity Numeric. used method \"bayesian_logistic_misclass\". ... Additional arguments pass Stan method \"bayesian_logistic_misclass\". Iterations chains default 2000 4 respectively.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Linear or Logistic Regression with TransPhylo Results — regression","text":"lm object, glm object, stanfit.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_TransPhylo.html","id":null,"dir":"Reference","previous_headings":"","what":"Run TransPhylo on a Set of Trees — run_TransPhylo","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"wrapper TransPhylo::infer_multittree_share_param. Can use run TransPhylo set trees, either MCC trees parameter sharing, sample posterior BEAST2 trees without parameter sharing (.e., sample BEAST2 posterior trees single cluster, incorporate phylogenetic uncertainty).","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_TransPhylo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"","code":"run_TransPhylo(   trees,   cluster_name = NULL,   type = c(\"mcctrees\", \"trees_sample\"),   cluster_dict,   out_dir = \"TransPhylo\",   output_name = \"tp_res\",   ... )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_TransPhylo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"trees ape multiPhylo object containing trees analyzed. type \"mcctrees\", MCC trees clusters, names trees need match names trees cluster dictionary. type \"trees_sample\", sample posterior BEAST2 trees single cluster, cluster name provided argument. cluster_name type \"trees_sample\", name cluster trees analyzed. match cluster name cluster dictionary. type \"mcctrees\", argument ignored. type character string specifying type trees analyzed. Can \"mcctrees\" \"trees_sample\". \"mcctrees\", function run TransPhylo MCC trees clusters. \"trees_sample\", function run TransPhylo sample posterior BEAST2 trees single cluster. cluster_dict data frame containing sample_id, cluster_name, collectdt sequence, output assign_snp_clusters. out_dir character string specifying directory TransPhylo results saved. output_name character string specifying name output file. ... Additional arguments passed TransPhylo::infer_multittree_share_param.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_TransPhylo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run TransPhylo on a Set of Trees — run_TransPhylo","text":"data frame containing probability sample infection source.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_beast2.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Command-Line BEAST2 — run_beast2","title":"Run Command-Line BEAST2 — run_beast2","text":"Run BEAST2 XML file. Tree files, log files, etc. written directory XML file.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_beast2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Command-Line BEAST2 — run_beast2","text":"","code":"run_beast2(   input_xml_path,   beast2_path = \"/Applications/\\\"BEAST 2.7.7\\\"/bin/beast\" )"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/run_beast2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Command-Line BEAST2 — run_beast2","text":"input_xml_path Character string. Path BEAST2 XML file. beast2_path Character string. Path BEAST2 executable.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/sample_BEAST2_trees.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample BEAST2 Trees — sample_BEAST2_trees","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"function takes BEAST2 posterior trees samples subset , making sure keep tree names.","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/sample_BEAST2_trees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"","code":"sample_BEAST2_trees(trees_file, n_trees, seed = NULL, out_dir = NULL)"},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/sample_BEAST2_trees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"trees_file string path BEAST2 posterior trees file. n_trees integer number trees sample. seed Optionally, seed use tree sampling. out_dir Optionally, string directory write sampled trees .","code":""},{"path":"https://jessalynnsebastian.github.io/beast2tpPipeline/reference/sample_BEAST2_trees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample BEAST2 Trees — sample_BEAST2_trees","text":"ape multiPhylo object containing tree sample.","code":""}]
